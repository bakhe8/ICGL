from typing import List, Optional, Dict, Any
import os
import re
from pathlib import Path
from .base import Agent, AgentResult, Problem, AgentRole
from ..utils.logging_config import get_logger
from ..kb.schemas import now

logger = get_logger(__name__)


class ArchivistAgent(Agent):
    """
    ðŸ“œ Sovereign Archivist (Council Clerk) - PROACTIVE MODE
    
    Responsibility: 
    Maintains the integrity and freshness of the Sovereign Archive 
    (Policies, Procedures, ADRs). Monitors for documentation gaps 
    and policy contradictions.
    
    ENHANCED CAPABILITIES:
    - Detects policies referenced in ADRs but missing as files
    - Generates policy drafts automatically
    - Submits formal requests for missing documentation
    - Creates comprehensive audit reports
    """
    
    def __init__(self, agent_id: str, llm_provider: Optional["LLMProvider"] = None):
        super().__init__(agent_id=agent_id, role=AgentRole.ARCHIVIST, llm_provider=llm_provider)
        # Fix: Resolve relative to project root (one level up from src if running as module)
        self.docs_root = Path(__file__).resolve().parents[3] / "docs"
        self.policies_dir = self.docs_root / "policies"
        self.drafts_dir = self.policies_dir / "drafts"
        self.adrs_dir = self.docs_root / "adrs"
        
        # Transparency: Store logs of the last audit Consultation
        self.last_consultation_logs = [] # List of {prompt: str, response: str, timestamp: str}

    def _scan_for_policy_references(self) -> List[str]:
        """
        Scan all ADRs for policy references (e.g., P-OPS-05, P-GOV-01).
        Returns list of policy codes found.
        """
        policy_pattern = re.compile(r'P-[A-Z]+-\d+')
        referenced_policies = set()
        
        if not self.adrs_dir.exists():
            return []
        
        for adr_file in self.adrs_dir.glob("*.md"):
            try:
                content = adr_file.read_text(encoding='utf-8')
                matches = policy_pattern.findall(content)
                referenced_policies.update(matches)
            except Exception as e:
                logger.warning(f"Failed to scan {adr_file}: {e}")
        
        return sorted(list(referenced_policies))

    def _check_policy_exists(self, policy_code: str) -> bool:
        """Check if a policy file exists."""
        if not self.policies_dir.exists():
            return False
        
        policy_file = self.policies_dir / f"{policy_code}.md"
        return policy_file.exists()

    def detect_missing_policies(self) -> List[str]:
        """
        Detect policies that are referenced but don't have corresponding files.
        """
        referenced = self._scan_for_policy_references()
        missing = [p for p in referenced if not self._check_policy_exists(p)]
        
        logger.info(f"ðŸ“‹ Policy Scan: {len(referenced)} referenced, {len(missing)} missing")
        return missing

    def generate_policy_draft(self, policy_code: str) -> str:
        """
        Generate a policy draft based on the policy code.
        This is a template that will be refined by LLM or human review.
        """
        # Extract policy type from code (e.g., P-OPS-05 -> OPS)
        parts = policy_code.split('-')
        policy_type = parts[1] if len(parts) > 1 else "GENERAL"
        
        policy_titles = {
            "P-OPS-05": "Foundational Autonomy Protocol",
            "P-GOV-01": "Sovereign Approval Authority",
            "P-SEC-02": "External Surface Control",
            "P-OBS-01": "Traceability & Auditability"
        }
        
        title = policy_titles.get(policy_code, f"{policy_type} Policy")
        
        draft = f"""# {policy_code}: {title}

**Status:** DRAFT  
**Effective Date:** TBD  
**Owner:** Office of the CEO  
**Department:** {policy_type}

---

## 1. Purpose

[To be defined: What is the purpose of this policy?]

---

## 2. Scope

This policy applies to:
- [Define scope]

---

## 3. Policy Statement

[Core policy rule/principle]

---

## 4. Requirements

All [agents/systems/departments] **SHALL**:

1. [Requirement 1]
2. [Requirement 2]
3. [Requirement 3]

---

## 5. Enforcement

Violations of this policy may result in:
- [Consequence 1]
- [Consequence 2]

---

## 6. Related Documents

- [Related ADRs]
- [Related Procedures]

---

**This is a DRAFT policy generated by ArchivistAgent. Requires sovereign review and approval.**
"""
        return draft

    async def generate_policy_with_llm(self, policy_code: str, context: str = "") -> str:
        """
        Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±ÙŠ (LLM) Ù„ØªÙˆÙ„ÙŠØ¯ Ø³ÙŠØ§Ø³Ø© Ø¨Ù…Ø¹Ø§ÙŠÙŠØ± Ø­Ø¯ÙŠØ«Ø©.
        
        Consult the Advisory Hub (LLM) to generate a high-quality policy draft.
        """
        if not self.llm:
            logger.warning("âš ï¸ LLM not available, using template-based generation")
            return self.generate_policy_draft(policy_code)
        
        policy_titles = {
            "P-OPS-05": "Foundational Autonomy Protocol",
            "P-GOV-01": "Sovereign Approval Authority",
            "P-SEC-02": "External Surface Control",
            "P-OBS-01": "Traceability & Auditability"
        }
        
        title = policy_titles.get(policy_code, f"Policy {policy_code}")
        
        prompt = f"""You are the Sovereign Archivist. Your task is to draft a FINALIZED policy document, NOT a template.
        
You must use the following context (critiques and analysis) to population the sections with REAL content.
        
Policy Code: {policy_code}
Policy Title: {title}

CONTEXT FROM AUDIT:
{context}

STRICT OUTPUT FORMAT (Markdown):

# {policy_code}: {title}

**Status:** DRAFT
**Effective Date:** TBD
**Owner:** Office of the CEO

## 1. Purpose
[Write 2-3 sentences explaining WHY this policy is needed, based on the context]

## 2. Scope
[List who this applies to - usually all Agents and Systems]

## 3. Policy Statement
[The core rule. Example: "All agents must verify X before Y"]

## 4. Requirements
[CRITICAL: Transform the analysis context into specific, numbered 'SHALL' or 'MUST' requirements. 
Do NOT use placeholders like '[Requirement 1]'. 
Example: 
1. The system SHALL log all access attempts.
2. Agents MUST verify identity before execution.
]

## 5. Enforcement
[Standard enforcement: Non-compliance leads to agent isolation or decommission.]

## 6. Related Documents
- [List relevant ADRs or SOPs if known, else standard governance docs]

---
**Generated by Sovereign AI Governance Engine**
"""
        
        try:
            from ..core.llm import LLMRequest
            from datetime import datetime
            
            request = LLMRequest(prompt=prompt, temperature=0.3, max_tokens=2000)
            response = await self.llm.generate(request)
            
            # Record for Transparency
            self.last_consultation_logs.append({
                "policy_code": policy_code,
                "prompt": prompt,
                "response": response.content,
                "timestamp": datetime.now().isoformat()
            })
            
            logger.info(f"âœ… Generated policy {policy_code} via LLM consultation")
            return response.content
        except Exception as e:
            logger.error(f"âŒ LLM consultation failed: {e}, falling back to template")
            return self.generate_policy_draft(policy_code)

    def detect_policy_contradictions(self, kb) -> List[Dict[str, str]]:
        """
        ÙØ­Øµ Ø§Ù„ØªØ¶Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚.
        
        Detect contradictions between policies, ADRs, and procedures.
        Returns list of potential conflicts.
        """
        contradictions = []
        
        # Example: Check if ADRs reference policies that don't exist
        # This is a simplified version - can be expanded with LLM analysis
        
        if not self.adrs_dir.exists():
            return contradictions
        
        for adr_file in self.adrs_dir.glob("*.md"):
            try:
                content = adr_file.read_text(encoding='utf-8')
                
                # Check for "REJECTED" ADRs that might conflict with "ACCEPTED" ones
                if "Status:** âœ… ACCEPTED" in content or "Status: ACCEPTED" in content:
                    # Look for contradictory statements
                    if "No Agent is permitted" in content and "Autonomous Execution" in content:
                        contradictions.append({
                            "type": "POTENTIAL_CONFLICT",
                            "file": str(adr_file),
                            "description": "ADR mentions both 'No Agent is permitted' and 'Autonomous Execution'"
                        })
            except Exception as e:
                logger.warning(f"Failed to check {adr_file}: {e}")
        
        return contradictions

    async def check_document_coherence(self, kb) -> Dict[str, Any]:
        """
        Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ±Ø§Ø¨Ø· Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙˆØ¹Ø¯Ù… ØªØ¶Ø§Ø±Ø¨Ù‡Ø§.
        
        Comprehensive coherence check across all governance documents.
        """
        coherence_report = {
            "status": "COHERENT",
            "issues": [],
            "recommendations": []
        }
        
        # 1. Check for missing policy files
        missing_policies = self.detect_missing_policies()
        if missing_policies:
            coherence_report["issues"].append({
                "severity": "HIGH",
                "type": "MISSING_POLICIES",
                "details": f"Policies referenced but not documented: {', '.join(missing_policies)}"
            })
            coherence_report["status"] = "GAPS_DETECTED"
        
        # 2. Check for contradictions
        contradictions = self.detect_policy_contradictions(kb)
        if contradictions:
            coherence_report["issues"].append({
                "severity": "MEDIUM",
                "type": "POTENTIAL_CONTRADICTIONS",
                "details": contradictions
            })
            if coherence_report["status"] == "COHERENT":
                coherence_report["status"] = "REVIEW_NEEDED"
        
        # 3. Check for orphaned ADRs (ADRs not linked to any policy)
        # This would require more sophisticated analysis
        
        # 4. Generate recommendations
        if missing_policies:
            coherence_report["recommendations"].append(
                "Create missing policy files to ensure complete documentation"
            )
        
        if contradictions:
            coherence_report["recommendations"].append(
                "Review potential contradictions and clarify policy boundaries"
            )
        
        return coherence_report


    async def audit_kb(self, kb) -> Dict[str, Any]:
        """
        Performs a comprehensive audit of the Knowledge Base and file system.
        """
        # Check KB
        kb_policies = len(kb.policies) if hasattr(kb, 'policies') else 0
        kb_procedures = len(kb.procedures) if hasattr(kb, 'procedures') else 0
        kb_decisions = len(kb.human_decisions) if hasattr(kb, 'human_decisions') else 0
        
        # Check file system
        missing_policies = self.detect_missing_policies()
        
        # Check if policies directory exists
        policies_dir_exists = self.policies_dir.exists()
        
        stats = {
            "policies_count_kb": kb_policies,
            "procedures_count": kb_procedures,
            "decisions_count": kb_decisions,
            "policies_dir_exists": policies_dir_exists,
            "missing_policy_files": missing_policies,
            "status": "HEALTHY",
            "gaps": []
        }
        
        # Detect gaps
        if not policies_dir_exists:
            stats["gaps"].append("CRITICAL: docs/policies/ directory does not exist")
            stats["status"] = "CRITICAL"
        
        if missing_policies:
            stats["gaps"].append(f"Missing {len(missing_policies)} policy files: {', '.join(missing_policies)}")
            stats["status"] = "WARNING" if stats["status"] != "CRITICAL" else "CRITICAL"
        
        if kb_procedures == 0:
            stats["gaps"].append("Missing Standard Operating Procedures (SOPs)")
            if stats["status"] == "HEALTHY":
                stats["status"] = "WARNING"
        
        return stats

    async def create_missing_policy_files(self, missing_policies: List[str]) -> Dict[str, str]:
        """
        Create draft files for missing policies.
        Returns dict of {policy_code: file_path}
        """
        # Ensure policies directory exists
        self.policies_dir.mkdir(parents=True, exist_ok=True)
        
        created_files = {}
        
        for policy_code in missing_policies:
            draft = self.generate_policy_draft(policy_code)
            policy_file = self.policies_dir / f"{policy_code}.md"
            
            try:
                policy_file.write_text(draft, encoding='utf-8')
                created_files[policy_code] = str(policy_file)
                logger.info(f"âœ… Created policy draft: {policy_file}")
            except Exception as e:
                logger.error(f"âŒ Failed to create {policy_code}: {e}")
        
        return created_files

    async def _analyze(self, problem: Problem, kb) -> AgentResult:
        """
        Analyzes the state of documentation and proposes enhancements.
        PROACTIVE MODE: Also creates missing policy drafts.
        
        All reports pass through SecretaryAgent before reaching CEO.
        """
        audit = await self.audit_kb(kb)
        
        analysis = f"Sovereign Archive Status: {audit['status']}. "
        analysis += f"KB contains {audit['policies_count_kb']} policies and {audit['procedures_count']} procedures. "
        
        if audit['missing_policy_files']:
            analysis += f"\n\nâš ï¸ DETECTED {len(audit['missing_policy_files'])} MISSING POLICY FILES: {', '.join(audit['missing_policy_files'])}"
        
        recs = []
        
        # Proactive action: Create missing policy drafts
        if audit['missing_policy_files']:
            created = await self.create_missing_policy_files(audit['missing_policy_files'])
            recs.append(f"CREATED_POLICY_DRAFTS: {len(created)} files")
            analysis += f"\n\nâœ… PROACTIVE ACTION: Created {len(created)} policy draft files for review."
        
        if audit["status"] == "WARNING" or audit["status"] == "CRITICAL":
            recs.append("EXPAND_PROCEDURE_LIBRARY")
            recs.append("REFINE_GOVERNANCE_DOCS")
        
        if not audit["policies_dir_exists"]:
            recs.append("CREATE_POLICIES_DIRECTORY")
        
        return AgentResult(
            agent_id=self.agent_id,
            role=self.role,
            analysis=analysis,
            recommendations=recs,
            confidence=0.95
        )

    async def submit_report_to_ceo(self, kb, secretary_agent=None, consultant_agent=None, mediator_agent=None) -> Dict[str, Any]:
        """
        Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ù„Ù„Ø±Ø¦ÙŠØ³.
        Workflow:
        1. Archivist generates findings.
        2. [New] Mediator controls access to Consultant (Cost/Traffic Control).
        3. Secretary formats and delivers.
        """
        # Generate findings
        audit = await self.audit_kb(kb)
        coherence = await self.check_document_coherence(kb)
        severity = audit.get("status", "MEDIUM")
        
        consultant_feedback = []
        
        # Route through Mediator if available
        if mediator_agent and consultant_agent:
            try:
                msg = f"Requesting consultation for Audit Report (Severity: {severity})"
                logger.info(f"ðŸš¦ Mediator Traffic Control: {msg}")
                
                request_data = {
                    "severity": severity,
                    "doc_type": "Audit Report",
                    "content": str(audit) + "\n" + str(coherence)
                }
                
                # Ask Mediator for permission/execution
                mediation_result = await mediator_agent.request_consultation(
                    requester_id=self.agent_id,
                    request_data=request_data,
                    consultant_agent=consultant_agent
                )
                
                if mediation_result["approved"]:
                    consultant_feedback.append(mediation_result["consultation_result"])
                    logger.info("âœ… Mediator Approved Consultation")
                else:
                    logger.info(f"â›” Mediator Denied Consultation: {mediation_result['reason']}")
                    consultant_feedback.append({"critique": f"Consultation Skipped: {mediation_result['reason']}", "score": -1})
                    
            except Exception as e:
                logger.warning(f"Mediator/Consultant failed: {e}")
        
        # Fallback: Direct consult if no Mediator (optional, but requested to enforce mediation)
        elif consultant_agent:
             # Just do direct call if no mediator provided (Legacy mode)
             pass
             
        # Prepare raw report
        raw_report = {
            "from": "ArchivistAgent",
            "to": "CEO",
            "timestamp": str(now()),
            "audit": audit,
            "coherence": coherence,
            "consultant_review": consultant_feedback, 
            "priority": "HIGH" if severity == "CRITICAL" else "MEDIUM"
        }
        
        # Route through Secretary
        if secretary_agent:
            return await secretary_agent.format_report_for_ceo(raw_report)
            
        return raw_report

    async def report_blocker(self, blocker_type: str, details: str, severity: str = "HIGH") -> Dict[str, str]:
        """
        Ø±ÙØ¹ ØªÙ‚Ø±ÙŠØ± Ù…Ø¹ÙˆÙ‚ Ù„Ù„Ø±Ø¦ÙŠØ³ Ø¹Ø¨Ø± Ø§Ù„Ù…ÙƒØªØ¨.
        
        Report a blocker to CEO through proper channels.
        """
        blocker_report = {
            "type": "BLOCKER",
            "severity": severity,
            "blocker_type": blocker_type,
            "details": details,
            "from": self.agent_id,
            "timestamp": str(now()),
            "requires_action": True
        }
        
        logger.critical(f"ðŸš¨ BLOCKER REPORTED: {blocker_type} - {details}")
        
        # This should be routed through SecretaryAgent in production
        # For now, just log and return
        return blocker_report

    async def create_drafts_from_plan(self, plan_data: Dict[str, Any]) -> List[str]:
        """
        Creates draft policy files in the drafts folder based on the improvement plan.
        """
        self.drafts_dir.mkdir(parents=True, exist_ok=True)
        created_drafts = []

        # Access content
        description = plan_data.get("consultant_plan", {}).get("description", "")
        raw_analysis = plan_data.get("consultant_plan", {}).get("raw_analysis", "")
        full_text = str(description) + "\n" + str(raw_analysis)

        # 1. Advanced Extraction: Try to find structured policy list
        policy_codes = self._extract_policies_from_text(full_text)
        
        if not policy_codes:
            # Fallback: Check if the consultant specifically mentioned a code in the summary
            import re
            policy_codes = set(re.findall(r'P-[A-Z]+-\d+', full_text))
            
        if not policy_codes:
            logger.info("âš ï¸ No specific policy codes identified, generating P-GEN-01 fallback.")
            policy_codes = {"P-GEN-01"}
            
        for code in policy_codes:
            # Prepare rich context for the Consultant
            llm_context = f"""
            IMPROVEMENT PLAN CONTEXT:
            Description: {description}
            Full Analysis: {raw_analysis}
            
            OBJECTIVE:
            Extract the core rules suggested by the consultant and formalize them into policy requirements.
            Address the specific flaws identified in the analysis.
            """
            
            draft_content = await self.generate_policy_with_llm(code, context=llm_context)
            
            # Write to drafts folder
            draft_file = self.drafts_dir / f"{code}.md"
            draft_file.write_text(draft_content, encoding='utf-8')
            created_drafts.append(code)
            logger.info(f"ðŸ“ Created ROBUST DRAFT: {draft_file}")
            
        return created_drafts

    def _extract_policies_from_text(self, text: str) -> set:
        """
        Attempts to find policy codes embedded in various formats (JSON, tags, lists).
        """
        codes = set()
        
        # A. Look for JSON block
        try:
            # Simple regex to find JSON-like structures
            import json
            json_blocks = re.findall(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
            for block in json_blocks:
                data = json.loads(block)
                if isinstance(data, dict):
                    # Look for "policies" or "required_policies" keys
                    list_data = data.get("policies") or data.get("required_policies")
                    if isinstance(list_data, list):
                        codes.update([str(p).split(":")[0].strip() for p in list_data])
        except Exception as e:
            logger.debug(f"JSON extraction failed: {e}")

        # B. Look for specific Tag: [POLICY: P-XXX-NN]
        tag_matches = re.findall(r'\[POLICY:\s*(P-[A-Z]+-\d+)\]', text)
        codes.update(tag_matches)
        
        # C. Look for explicit mentions in markdown headers or lists
        # e.g. "## Proposed Policy: P-SEC-03"
        header_matches = re.findall(r'Proposed Policy:\s*(P-[A-Z]+-\d+)', text)
        codes.update(header_matches)

        return codes

    async def ratify_drafts(self) -> List[str]:
        """
        Moves all files from drafts folder to policies folder.
        This is the formal ratification step.
        """
        if not self.drafts_dir.exists():
            return []
            
        ratified_policies = []
        
        for draft_file in self.drafts_dir.glob("*.md"):
            # Destination path
            policy_file = self.policies_dir / draft_file.name
            
            # Move file
            draft_file.rename(policy_file)
            ratified_policies.append(draft_file.stem)
            logger.info(f"âœ… RATIFIED Policy: {policy_file}")
            
        return ratified_policies

    async def generate_improvement_plan(self, consultant_agent) -> Dict[str, Any]:
        """
        Safe Experiment:
        Audits the current document structure and consults with AI
        for improvements WITHOUT making changes.
        """
        # 1. Gather Inventory
        inventory = {
            "policies": [],
            "adrs": [],
            "root_docs": []
        }
        
        # Scan Policies
        if self.policies_dir.exists():
            for f in self.policies_dir.glob("*.md"):
                inventory["policies"].append(f.name)
                
        # Scan ADRs
        if self.adrs_dir.exists():
            for f in self.adrs_dir.glob("*.md"):
                inventory["adrs"].append(f.name)
                
        # Scan Root
        for f in self.docs_root.glob("*.md"):
            inventory["root_docs"].append(f.name)

        # 2. Consult
        if consultant_agent:
            prompt_content = f"""
            Current Documentation Structure:
            - Policies: {inventory['policies']}
            - ADRs: {inventory['adrs']}
            - General Docs: {inventory['root_docs']}
            
            Task:
            Analyze this structure. 
            1. Identify missing critical policies (e.g., Access Control, Data Privacy).
            2. Suggest a cleaner folder structure if needed.
            3. Propose a renaming scheme if inconsistent.
            
            Output JSON:
            {{
                "missing_policies": ["CODE: Title (e.g. P-SEC-01: Access Control)"],
                "required_policies": ["P-SEC-01", "P-DAT-02"],
                "structure_feedback": "Detailed analysis of current state",
                "proposed_actions": ["Action 1", "Action 2"]
            }}
            
            CRITICAL: Ensure the "required_policies" key contains a clean list of P-XXX-NN codes.
            """
            
            try:
                # Reuse review_document_draft as a generic pipe for now
                review = await consultant_agent.review_document_draft(
                    doc_type="Structure Audit",
                    content=prompt_content
                )
                
                return {
                    "current_state": inventory,
                    "consultant_plan": review,
                    "status": "PLAN_READY",
                    "next_step": "User Approval"
                }
            except Exception as e:
                return {"error": str(e)}
        
        return {"error": "No Consultant Available"}
