import asyncio
import json
import os
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
from fastapi import BackgroundTasks, FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.encoders import jsonable_encoder
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, RedirectResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

# Import central engine dependency
from backend.api.deps import get_icgl
from backend.api.schemas import OperationResult

# --- IMPORTS FROM SHARED ---
from shared.python.kb.schemas import ADR, now, uid
from shared.python.utils.logging_config import get_logger

# 1. üî¥ MANDATORY: Load Environment FIRST (Root Cause Fix for OpenAI Key)
# We find the .env relative to this file's root
# backend/api/server.py -> parent=api, parent=backend, parent=root (3 parents)
BASE_DIR = Path(__file__).parent.parent.parent
env_path = BASE_DIR / ".env"
load_dotenv(dotenv_path=env_path)

# Initialize logger
logger = get_logger(__name__)

if not os.getenv("OPENAI_API_KEY"):
    logger.warning("‚ùå OPENAI_API_KEY NOT FOUND IN ENVIRONMENT!")

# Initialize FastAPI
app = FastAPI(title="ICGL Sovereign Cockpit API", version="1.2.0")

# Root app that will expose the UI at `/` and mount the API at `/api`.
# We keep the existing `app` as the API application and expose a top-level
# `app` (reassigned later) so uvicorn can run the root application.
root_app = FastAPI(title="ICGL Root")

# Allow CORS on the root app (wraps mounted API as well)
root_app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Global Engine Singleton Move ---
# Functionality relocated to backend.api.deps.get_icgl


# --- Dashboard / App Mounting ---
# Prefer the frontend build in `frontend/web-app/dist` (monorepo layout).
# Also keep the legacy `backend/web/dist` path for backwards compatibility.
candidate_paths = [
    BASE_DIR / "frontend" / "web-app" / "dist",
    Path(__file__).parent.parent / "web" / "dist",
]
ui_path = None
for p in candidate_paths:
    if p.exists():
        ui_path = p
        break

if ui_path:
    # Mount at both /app and /dashboard on the root app so UI is reachable
    # at the top-level paths while the API is mounted under `/api`.
    root_app.mount("/app", StaticFiles(directory=str(ui_path), html=True), name="ui_app")
    root_app.mount("/dashboard", StaticFiles(directory=str(ui_path), html=True), name="ui_dashboard")
    logger.info(f"‚úÖ UI loaded from {ui_path} (mounted at /app and /dashboard)")
else:
    logger.warning(
        f"‚ö†Ô∏è UI path not found. Expected one of: {[str(p) for p in candidate_paths]}. Run frontend build and try again."
    )


# Pragmatic root redirect to the UI entry so requests to `/` land on the SPA.
@root_app.get("/", include_in_schema=False)
async def root_redirect():
    return RedirectResponse(url="/app/")


# Convenience redirects so the legacy `/docs`, `/redoc` and OpenAPI JSON
# remain reachable at their traditional top-level paths even though the
# API is mounted under `/api`.
from fastapi.openapi.docs import get_redoc_html, get_swagger_ui_html, get_swagger_ui_oauth2_redirect_html  # noqa: E402


@root_app.get("/docs", include_in_schema=False)
async def docs_ui():
    """Serve Swagger UI for the mounted API at `/api` but expose it at `/docs`."""
    return get_swagger_ui_html(openapi_url="/api/openapi.json", title="ICGL API Docs")


@root_app.get("/docs/oauth2-redirect", include_in_schema=False)
async def swagger_oauth2_redirect():
    return get_swagger_ui_oauth2_redirect_html()


@root_app.get("/redoc", include_in_schema=False)
async def redoc_ui():
    return get_redoc_html(openapi_url="/api/openapi.json", title="ICGL ReDoc")


@root_app.get("/openapi.json", include_in_schema=False)
async def openapi_schema():
    # Return the OpenAPI schema generated by the mounted API app.
    try:
        schema = app.openapi()
    except Exception:
        # Fallback: call the internal API app's OpenAPI generator if available
        schema = None
    if schema is None:
        raise HTTPException(status_code=500, detail="OpenAPI schema not available")
    return JSONResponse(content=schema)


# Expose the mounted API application's OpenAPI schema explicitly at
# `/api/openapi.json` so the Swagger UI (which points to `/api/openapi.json`)
# reliably sees the API routes even when apps are mounted or wrapped.
@root_app.get("/api/openapi.json", include_in_schema=False)
async def api_openapi_schema():
    try:
        schema = app.openapi()
    except Exception as e:
        logger.warning(f"Could not generate API OpenAPI schema: {e}")
        raise HTTPException(status_code=500, detail="API OpenAPI schema not available")
    return JSONResponse(content=schema)


# --- State ---
active_synthesis: Dict[str, Any] = {}
global_telemetry = {"drift_detection_count": 0, "agent_failure_count": 0}


# --- WebSocket Manager ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        """Broadcast message to all connected WebSocket clients."""
        dead_connections = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except (WebSocketDisconnect, RuntimeError):
                # Connection closed, mark for removal
                dead_connections.append(connection)
            except Exception as e:
                logger.warning(f"Broadcast error: {e}")

        # Clean up dead connections
        for conn in dead_connections:
            if conn in self.active_connections:
                self.active_connections.remove(conn)


manager = ConnectionManager()
scp_manager = ConnectionManager()


# --- Models ---
class ProposalRequest(BaseModel):
    title: str
    context: str
    decision: str
    human_id: str = "bakheet"


class SignRequest(BaseModel):
    action: str
    rationale: str
    human_id: str = "bakheet"


# --- Diagnostic Endpoints ---


from backend.api.schemas import (  # noqa: E402
    EventsResp,
    GenericDataResp,
    HealthResp,
    ObservabilityStatsResp,
    TraceDetailsResp,
    TracesResp,
)


@app.get("/health", response_model=HealthResp)
async def health_check() -> HealthResp:
    """Diagnostic endpoint to verify system sanity."""
    status: Dict[str, Any] = {
        "api": "healthy",
        "env_loaded": bool(os.getenv("OPENAI_API_KEY")),
        "db_lock": "unknown",
        "engine_ready": get_icgl() is not None,
    }

    try:
        icgl = get_icgl()
        status["engine_ready"] = True
        # Test KB
        icgl.kb.get_adr("test")  # Simple query
        status["db_lock"] = "none"
    except Exception as e:
        status["api"] = "degraded"
        status["db_error"] = str(e)

    return HealthResp(
        api=status.get("api", "unknown"),
        env_loaded=status.get("env_loaded", False),
        db_lock=status.get("db_lock", None),
        engine_ready=status.get("engine_ready", False),
        db_error=status.get("db_error", None),
    )


@app.get("/status", response_model=GenericDataResp)
async def get_status() -> GenericDataResp:
    try:
        icgl = get_icgl()
        last_adr = None
        adrs = list(icgl.kb.adrs.values())
        if adrs:
            last_adr = sorted(adrs, key=lambda x: x.created_at, reverse=True)[0]

        # Calculate Alert Level
        alert_level = "NONE"
        last_latency = 0

        if last_adr and last_adr.sentinel_signals:
            if any("üö®" in s or "CRITICAL" in s for s in last_adr.sentinel_signals):
                alert_level = "CRITICAL"
            elif any("‚ö†Ô∏è" in s or "WARNING" in s for s in last_adr.sentinel_signals):
                alert_level = "HIGH"

        if last_adr and last_adr.id in active_synthesis:
            last_latency = active_synthesis[last_adr.id].get("latency_ms", 0)

        return GenericDataResp(
            data={
                "mode": "COCKPIT",
                "waiting_for_human": last_adr.status == "DRAFT" if last_adr else False,
                "active_alert_level": alert_level,
                "last_adr_id": last_adr.id if last_adr else None,
                "telemetry": {**global_telemetry, "last_latency_ms": last_latency},
            }
        )
    except Exception as e:
        return GenericDataResp(data={"mode": "ERROR", "error": str(e)})


@app.post("/propose", response_model=OperationResult)
async def propose_decision(req: ProposalRequest, background_tasks: BackgroundTasks) -> OperationResult:
    logger.info(f"üìù Proposal Received: {req.title}")
    try:
        icgl = get_icgl()
        adr = ADR(
            id=uid(),
            title=req.title,
            status="DRAFT",
            context=req.context,
            decision=req.decision,
            consequences=[],
            related_policies=[],
            sentinel_signals=[],
            human_decision_id=None,
        )

        icgl.kb.add_adr(adr)
        active_synthesis[adr.id] = {"status": "processing"}

        background_tasks.add_task(run_analysis_task, adr, req.human_id)
        return OperationResult(status="Analysis Triggered", result={"adr_id": adr.id})
    except Exception as e:
        logger.error(f"Proposal Error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.websocket("/ws/status")
async def websocket_status(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            # Keep connection alive, we primarily broadcast to them
            _data = await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket)


@app.websocket("/ws/analysis/{adr_id}")
async def websocket_analysis(websocket: WebSocket, adr_id: str):
    """WebSocket endpoint for real-time analysis updates."""
    await websocket.accept()
    try:
        while True:
            if adr_id in active_synthesis:
                await websocket.send_json(active_synthesis[adr_id])
                if active_synthesis[adr_id].get("status") == "complete" or "synthesis" in active_synthesis[adr_id]:
                    break  # Done
            await asyncio.sleep(1)
    except WebSocketDisconnect:
        logger.info(f"Client disconnected from analysis/{adr_id}")
    except Exception as e:
        logger.warning(f"Error in analysis stream for {adr_id}: {e}")
        try:
            await websocket.send_json({"error": "Analysis stream error", "message": str(e)})
        except Exception:
            pass  # Client already gone
    finally:
        try:
            await websocket.close()
        except Exception:
            pass  # Already closed


async def run_analysis_task(adr: ADR, human_id: str) -> None:
    """Background task to run full ICGL analysis on an ADR."""
    import time

    start_time = time.time()
    logger.info(f"üåÄ Starting Background Analysis for {adr.id}")
    try:
        icgl = get_icgl()
        from shared.python.agents.base import Problem

        # Policy gate check (pre-analysis)
        policy_report = icgl.enforcer.check_adr_compliance(adr)
        if policy_report.status == "FAIL":
            active_synthesis[adr.id] = {"status": "blocked", "policy_report": policy_report.__dict__}
            return

        # 1. Semantic Search (Historical Echo / S-11)
        query = f"{adr.title} {adr.context} {adr.decision}"
        matches = await icgl.memory.search(query, limit=4)
        semantic = []
        for m in matches:
            if m.document.id != adr.id:
                semantic.append(
                    {
                        "id": m.document.id,
                        "title": m.document.metadata.get("title", "Unknown"),
                        "score": round(m.score * 100, 1),
                    }
                )

        # 2. Sentinel Detailed Scan
        alerts = await icgl.sentinel.scan_adr_detailed_async(adr, icgl.kb)
        if any(a.category.value == "Drift" for a in alerts):
            global_telemetry["drift_detection_count"] += 1

        # 3. Agent Synthesis
        problem = Problem(title=adr.title, context=adr.context, metadata={"decision": adr.decision})

        synthesis = await icgl.registry.run_and_synthesize(problem, icgl.kb)

        from dataclasses import asdict

        active_synthesis[adr.id] = {
            "adr": asdict(adr),
            "synthesis": {
                "overall_confidence": synthesis.overall_confidence,
                "consensus_recommendations": synthesis.consensus_recommendations,
                "all_concerns": synthesis.all_concerns,
                "agent_results": [asdict(r) for r in synthesis.individual_results],
                "semantic_matches": semantic[:3],
                "sentinel_alerts": [
                    {"id": a.rule_id, "severity": a.severity.value, "message": a.message, "category": a.category.value}
                    for a in alerts
                ],
                "mindmap": generate_consensus_mindmap(adr.title, synthesis),
                "mediation": None,  # Placeholder
                "policy_report": policy_report.__dict__,
            },
        }

        # 4. Mediation Mode (Phase G) if ÿßŸÑÿ´ŸÇÿ© ŸÖŸÜÿÆŸÅÿ∂ÿ©
        if synthesis.overall_confidence < 0.7:
            logger.info(f"‚öñÔ∏è Consensus Low ({synthesis.overall_confidence:.2f}). Invoking Mediator...")
            from shared.python.agents.mediator import MediatorAgent

            llm_provider = icgl.registry.get_llm_provider() if hasattr(icgl.registry, "get_llm_provider") else None
            mediator = MediatorAgent(llm_provider=llm_provider)

            problem_mediation = Problem(
                title=adr.title,
                context=adr.context,
                metadata={"decision": adr.decision, "agent_results": [asdict(r) for r in synthesis.individual_results]},
            )
            mediation_result = await mediator.analyze(problem_mediation, icgl.kb)

            active_synthesis[adr.id]["synthesis"]["mediation"] = {
                "analysis": mediation_result.analysis,
                "confidence": mediation_result.confidence,
                "concerns": mediation_result.concerns,
            }
            logger.info("‚öñÔ∏è Mediation Complete.")

        # FINAL BROADCAST
        await manager.broadcast({"type": "status_update", "status": await get_status()})

        # SCP BROADCAST (Real-time alerts)
        if alerts:
            for alert in alerts:
                await scp_manager.broadcast(
                    {
                        "id": f"alert-{uid()}",
                        "type": "alert",
                        "event_type": "sentinel_signal",
                        "message": alert.message,
                        "source": "Sentinel",
                        "severity": alert.severity.value.lower()
                        if hasattr(alert.severity, "value")
                        else str(alert.severity).lower(),
                        "timestamp": now(),
                    }
                )

        # Update ADR in KB with signals
        adr.sentinel_signals = [str(a) for a in alerts]
        icgl.kb.add_adr(adr)

        duration = round((time.time() - start_time) * 1000)
        active_synthesis[adr.id]["latency_ms"] = duration

        logger.info(f"‚ú® Analysis Complete for {adr.id} ({duration}ms)")
        return active_synthesis[adr.id]
    except Exception as e:
        global_telemetry["agent_failure_count"] += 1
        logger.error(f"Async Analysis Failure: {e}", exc_info=True)
        active_synthesis[adr.id] = {"status": "failed", "error": str(e)}
        return active_synthesis[adr.id]


@app.get("/analysis/latest", response_model=GenericDataResp)
async def get_latest_analysis() -> GenericDataResp:
    """Gets the analysis of the most recent ADR."""
    icgl = get_icgl()
    adrs = list(icgl.kb.adrs.values())
    if not adrs:
        return GenericDataResp(data={"error": "No ADRs found"})

    # Sort by creation time desc
    last_adr = sorted(adrs, key=lambda x: x.created_at, reverse=True)[0]

    # Return active analysis if available, otherwise just ADR basics
    if last_adr.id in active_synthesis:
        return GenericDataResp(data=active_synthesis[last_adr.id])

    return GenericDataResp(data={"adr": last_adr.__dict__, "status": "no_active_analysis"})


@app.get("/idea-summary/{adr_id}", response_model=GenericDataResp)
async def get_idea_summary(adr_id: str) -> GenericDataResp:
    """Gets a simplified summary of an ADR."""
    icgl = get_icgl()
    adr = icgl.kb.get_adr(adr_id)
    if not adr:
        raise HTTPException(status_code=404, detail="ADR not found")

    return GenericDataResp(
        data={
            "id": adr.id,
            "title": adr.title,
            "status": adr.status,
            "context": adr.context[:200] + "..." if len(adr.context) > 200 else adr.context,
            "created_at": adr.created_at,
        }
    )


@app.get("/patterns/alerts", response_model=GenericDataResp)
async def get_pattern_alerts(limit: int = 20) -> GenericDataResp:
    """aggregates sentinel alerts from active analysis and KB."""
    try:
        icgl = get_icgl()
        alerts = []

        # 1. Collect from active synthesis (Structured)
        for adr_id, data in active_synthesis.items():
            if "synthesis" in data and "sentinel_alerts" in data["synthesis"]:
                for a in data["synthesis"]["sentinel_alerts"]:
                    alerts.append(
                        {
                            "alert_id": a.get("id", f"alert-{uid()}"),
                            "pattern": a.get("category", "General"),
                            "severity": a.get("severity", "medium").lower(),
                            "description": a.get("message", ""),
                            "timestamp": now(),
                            "event_count": 1,
                        }
                    )

        # 2. Collect from historical ADRs (parsed from strings if possible, or mocked for demo)
        # Since ADR.sentinel_signals are strings, we will just wrap them if needed.
        # For now, let's rely on active_synthesis + some mock historical data if empty to show UI.

        if not alerts:
            # Add a safe system heartbeat alert if empty, just so UI isn't blank during demo
            alerts.append(
                {
                    "alert_id": f"sys-{uid()}",
                    "pattern": "System Integrity",
                    "severity": "low",
                    "description": "Routine system scan completed. No anomalies detected.",
                    "timestamp": now(),
                    "event_count": 0,
                }
            )

        return GenericDataResp(data={"alerts": alerts[:limit]})
    except Exception as e:
        logger.error(f"Alerts Fetch Error: {e}")
        return GenericDataResp(data={"alerts": []})


@app.get("/channels", response_model=GenericDataResp)
async def get_channels_list() -> GenericDataResp:
    """Returns mock active channels for SCP Channels page."""
    import random

    mock_channels = []
    agents = ["Executive", "Governance", "Engineer", "Sentinel", "User"]

    for i in range(5):
        from_agent = random.choice(agents)
        to_agent = random.choice([a for a in agents if a != from_agent])

        mock_channels.append(
            {
                "channel_id": f"ch-{uid()}",
                "from_agent": from_agent,
                "to_agent": to_agent,
                "status": random.choice(["active", "active", "idle"]),
                "message_count": random.randint(10, 500),
                "violation_count": random.randint(0, 5),
                "policy": {"name": "Standard Access Protocol"},
            }
        )

    return GenericDataResp(data={"channels": mock_channels})


@app.get("/channels/stats", response_model=GenericDataResp)
async def get_channel_stats() -> GenericDataResp:
    """Returns mock channel stats for SCP Overview."""
    # In a real app, this would query the database or the channels service.
    # For now, we mock it to support the UI.
    return GenericDataResp(
        data={"active_channels": 12, "closed_channels": 45, "total_messages": 12450, "total_violations": 3}
    )


@app.get("/analysis/{adr_id}", response_model=GenericDataResp)
async def get_analysis(adr_id: str) -> GenericDataResp:
    if adr_id in active_synthesis:
        return GenericDataResp(data=active_synthesis[adr_id])
    raise HTTPException(status_code=404, detail="Analysis session context lost or not started.")


@app.post("/sign/{adr_id}", response_model=OperationResult)
async def sign_decision(adr_id: str, req: SignRequest) -> OperationResult:
    try:
        icgl = get_icgl()
        adr = icgl.kb.get_adr(adr_id)
        if not adr:
            raise HTTPException(status_code=404, detail="ADR not found")

        result_data = active_synthesis.get(adr_id)
        if not result_data or "synthesis" not in result_data:
            raise HTTPException(status_code=400, detail="Synthesis data missing.")

        # Block on policy or sentinel critical
        pol = result_data["synthesis"].get("policy_report")
        if pol and pol.get("status") == "FAIL":
            raise HTTPException(status_code=400, detail="Policy gate failed; cannot sign.")
        alerts = result_data["synthesis"].get("sentinel_alerts") or []
        if any(a.get("severity") == "CRITICAL" for a in alerts):
            raise HTTPException(status_code=400, detail="Critical sentinel alert; cannot sign.")

        # Record Decision
        decision = icgl.hdal.sign_decision(adr_id, req.action, req.rationale, req.human_id)

        # Persistence
        adr.status = "ACCEPTED" if req.action == "APPROVE" else "REJECTED"
        adr.human_decision_id = decision.id
        icgl.kb.add_adr(adr)
        icgl.kb.add_human_decision(decision)

        # Execution (Cycle 9)
        if req.action == "APPROVE" and getattr(icgl, "engineer", None):
            all_changes = []
            for res in result_data["synthesis"]["agent_results"]:
                if "file_changes" in res and res["file_changes"]:
                    from shared.python.kb.schemas import FileChange

                    all_changes.extend([FileChange(**fc) for fc in res["file_changes"]])

            if all_changes:
                for change in all_changes:
                    icgl.engineer.write_file(change.path, change.content)
                icgl.engineer.commit_decision(adr, decision)

        return OperationResult(status="Complete", result={"action": req.action})
    except Exception as e:
        logger.error(f"Sign Failure: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/policies")
async def get_policies():
    """Returns mock policies for PolicyEditor.tsx. Returns direct dict to match frontend fetch."""
    return {
        "policies": [
            {
                "name": "Standard Access Protocol",
                "description": "Default policy for standard user interactions.",
                "type": "static",
                "allowed_actions": ["READ_KB", "QUERY_SENTINEL"],
                "max_messages": 100,
                "max_duration_seconds": 300,
                "requires_human_approval": False,
                "conditions_count": 0,
                "alert_on_violations": True,
            },
            {
                "name": "High Security Containment",
                "description": "Strict isolation for sensitive assets.",
                "type": "conditional",
                "allowed_actions": ["REQUEST_APPROVAL", "REQUEST_REVIEW"],
                "max_messages": 10,
                "max_duration_seconds": 60,
                "requires_human_approval": True,
                "conditions_count": 2,
                "alert_on_violations": True,
            },
            {
                "name": "Analysis Mode",
                "description": "Allows extended duration for research.",
                "type": "static",
                "allowed_actions": ["READ_KB", "SHARE_ANALYSIS", "PROPOSE_CHANGE"],
                "max_messages": 500,
                "max_duration_seconds": 3600,
                "requires_human_approval": False,
                "conditions_count": 0,
                "alert_on_violations": False,
            },
        ]
    }


@app.get("/policies/{policy_name}")
async def get_policy_details(policy_name: str):
    """Returns details for a specific policy."""
    # For mock purposes, regenerate the list and find it.
    # In real app, query DB.
    policies = [
        {
            "name": "Standard Access Protocol",
            "description": "Default policy for standard user interactions.",
            "type": "static",
            "allowed_actions": ["READ_KB", "QUERY_SENTINEL"],
            "max_messages": 100,
            "max_duration_seconds": 300,
            "requires_human_approval": False,
            "conditions_count": 0,
            "alert_on_violations": True,
        },
        {
            "name": "High Security Containment",
            "description": "Strict isolation for sensitive assets.",
            "type": "conditional",
            "allowed_actions": ["REQUEST_APPROVAL", "REQUEST_REVIEW"],
            "max_messages": 10,
            "max_duration_seconds": 60,
            "requires_human_approval": True,
            "conditions_count": 2,
            "alert_on_violations": True,
            "conditions": [
                {"type": "env", "operator": "equals", "value": "secure_zone"},
                {"type": "time", "operator": "between", "value": "09:00-17:00"},
            ],
        },
        {
            "name": "Analysis Mode",
            "description": "Allows extended duration for research.",
            "type": "static",
            "allowed_actions": ["READ_KB", "SHARE_ANALYSIS", "PROPOSE_CHANGE"],
            "max_messages": 500,
            "max_duration_seconds": 3600,
            "requires_human_approval": False,
            "conditions_count": 0,
            "alert_on_violations": False,
        },
    ]

    for p in policies:
        if p["name"] == policy_name:
            return p

    # Fallback if not found (or return 404)
    from fastapi import HTTPException

    raise HTTPException(status_code=404, detail="Policy not found")


@app.get("/kb/{type}", response_model=GenericDataResp)
async def list_kb(type: str) -> GenericDataResp:
    try:
        icgl = get_icgl()
        if type == "adrs":
            return GenericDataResp(
                data={
                    "adrs": [
                        a.__dict__
                        for a in sorted(list(icgl.kb.adrs.values()), key=lambda x: x.created_at, reverse=True)
                    ]
                }
            )
        if type == "policies":
            return GenericDataResp(data={"policies": [p.__dict__ for p in list(icgl.kb.policies.values())]})
        return GenericDataResp(data={"error": "Invalid KB type"})
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def generate_consensus_mindmap(title: str, synthesis) -> str:
    """Generates Mermaid mindmap syntax from synthesis results."""
    lines: List[str] = ["mindmap", f"  root(({title}))"]

    # Consensus Node
    lines.append("    Consensus")
    for rec in synthesis.consensus_recommendations[:3]:
        # Clean text for Mermaid (no special chars)
        clean_rec = rec.replace("(", "[").replace(")", "]").replace('"', "'")
        lines.append(f"      {clean_rec}")

    # Agents Node
    lines.append("    Agents")
    for res in synthesis.individual_results:
        role = res.role.value
        conf = int(res.confidence * 100)
        lines.append(f"      {role} ({conf}%)")
        if res.concerns:
            first_concern = res.concerns[0].replace("(", "[").replace(")", "]")
            lines.append(f"        {first_concern}")

    # Risks Node
    if synthesis.all_concerns:
        lines.append("    Risks")
        for concern in synthesis.all_concerns[:3]:
            clean_concern = concern.replace("(", "[").replace(")", "]")
            lines.append(f"      {clean_concern}")

    return "\n".join(lines)


# =============================================================================
# üí¨ CHAT ENDPOINT (Conversational Interface)
# =============================================================================

from shared.python.chat.schemas import ChatRequest, ChatResponse  # noqa: E402
from shared.python.conversation import ConversationOrchestrator  # noqa: E402

# Initialize chat orchestrator (uses governed ICGL + Runtime Guard)
chat_orchestrator = ConversationOrchestrator(get_icgl, run_analysis_task)
chat_ws_manager = ConnectionManager()


@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    Conversational interface endpoint.

    User sends natural language message, system responds with rich structured content.
    """
    try:
        logger.info(f"üí¨ Chat message: {request.message[:80]}...")
        response = await chat_orchestrator.handle(request)
        # Broadcast to connected chat clients (stateful viewers)
        try:
            await chat_ws_manager.broadcast(jsonable_encoder(response))
        except Exception as e:
            logger.warning(f"Chat broadcast failed: {e}")
        return response
    except Exception as e:
        logger.error(f"Chat error: {e}", exc_info=True)
        return chat_orchestrator.composer.error(str(e))


@app.websocket("/ws/scp")
async def websocket_scp(websocket: WebSocket):
    """
    Sentinel Continuous Protection (SCP) stream.
    Broadcasts real-time alerts from the governance engine.
    """
    import asyncio
    import random

    await websocket.accept()
    try:
        # Send an initial welcome/status event
        await websocket.send_json(
            {
                "id": "scp-init",
                "type": "event",
                "data": {  # Wrapped in data to match frontend expectation
                    "event_type": "status",
                    "status": "success",
                    "actor_id": "Sentinel",
                    "action": "SYSTEM_INIT",
                    "message": "Sentinel Continuous Protection ACTIVE",
                    "timestamp": now(),
                },
            }
        )

        while True:
            # Simulate real-time events for the demo
            await asyncio.sleep(3)

            # Create a mock event
            event = {
                "event_type": random.choice(["USER_ACTION", "SYSTEM_ALERT", "POLICY_VIOLATION"]),
                "actor_id": random.choice(["user-123", "system-ai", "sentinel-bot"]),
                "action": random.choice(["LOGIN", "FILE_ACCESS", "CONFIG_CHANGE", "ANOMALY_DETECTED"]),
                "status": random.choice(["success", "success", "failure"]),
                "timestamp": now(),
                "target": "system.core.module",
                "error_message": "Access denied" if random.random() > 0.8 else None,
            }

            await websocket.send_json({"type": "event", "data": event})

    except WebSocketDisconnect:
        logger.info("SCP WebSocket disconnected")
    except Exception as e:
        logger.warning(f"SCP WS error: {e}")
        try:
            await websocket.close()
        except:
            pass


@app.websocket("/ws/chat")
async def websocket_chat(websocket: WebSocket):
    await chat_ws_manager.connect(websocket)
    try:
        # send a lightweight ack
        await websocket.send_json({"type": "stream", "content": "Connected via Secure Uplink."})

        while True:
            data_str = await websocket.receive_text()
            try:
                data = json.loads(data_str)
                user_content = data.get("content", "")

                # Create a mock Request object since Orchestrator expects one
                chat_req = ChatRequest(message=user_content)

                # Signal "Thinking" - Let frontend know we are working on it
                await websocket.send_json({"type": "stream", "content": ""})

                logger.info(f"‚è≥ Processing Chat Request: {user_content[:50]}...")
                start_ts = time.time()

                try:
                    # Process via Orchestrator with timeout safety
                    response = await asyncio.wait_for(chat_orchestrator.handle(chat_req), timeout=25.0)
                except asyncio.TimeoutError:
                    logger.error("‚ùå Orchestrator Timeout (25s)")
                    await websocket.send_json(
                        {
                            "type": "stream",
                            "content": "‚ö†Ô∏è System Timeout: Core reasoning took too long. Please try a simpler request.",
                        }
                    )
                    continue

                duration = time.time() - start_ts
                logger.info(f"‚úÖ Chat Processed in {duration:.2f}s")

                # Send text response(s) from assistant messages
                for msg in response.messages:
                    if msg.role == "assistant":
                        # Stream text
                        if msg.content:
                            await websocket.send_json({"type": "stream", "content": msg.content})

                        # Send blocks
                        if msg.blocks:
                            for block in msg.blocks:
                                await websocket.send_json(
                                    {
                                        "type": "block",
                                        "block_type": block.type,
                                        "title": block.title,
                                        "content": block.data,
                                    }
                                )

            except json.JSONDecodeError:
                pass
            except Exception as e:
                logger.error(f"WS Handling Error: {e}")
                await websocket.send_json({"type": "stream", "content": f"System Error: {str(e)}"})

    except WebSocketDisconnect:
        chat_ws_manager.disconnect(websocket)
    except Exception as e:
        logger.warning(f"Chat WS error: {e}")
        try:
            await websocket.send_json({"error": str(e)})
        except Exception:
            pass
        chat_ws_manager.disconnect(websocket)


@app.websocket("/ws/terminal")
async def websocket_terminal(websocket: WebSocket):
    """Minimal interactive terminal WebSocket used by the frontend.

    This endpoint echoes received commands and streams simple status
    messages. It's intentionally lightweight and safe.
    """
    await websocket.accept()
    try:
        await websocket.send_json({"type": "connected", "message": "Terminal connected."})
        while True:
            try:
                msg = await websocket.receive_text()
            except WebSocketDisconnect:
                break
            # Echo back as a structured output block
            try:
                await websocket.send_json({"type": "output", "content": f"Received: {msg}"})
            except Exception:
                break
    except Exception as e:
        logger.warning(f"Terminal WS error: {e}")
        try:
            await websocket.send_json({"error": str(e)})
        except Exception:
            pass


# =============================================================================
# üìä OBSERVABILITY ENDPOINTS (Phase 1: Read-Only)
# =============================================================================


@app.get("/observability/stats", response_model=ObservabilityStatsResp)
async def get_observability_stats():
    """Get observability ledger statistics"""
    try:
        from shared.python.observability import get_ledger

        ledger = get_ledger()
        if not ledger:
            return ObservabilityStatsResp(stats={"status": "not_initialized"})
        return ObservabilityStatsResp(stats=ledger.get_stats())
    except Exception as e:
        logger.error(f"Observability stats error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/observability/traces", response_model=TracesResp)
async def list_recent_traces(limit: int = 50):
    """List recent traces with metadata"""
    try:
        from shared.python.observability import get_ledger

        ledger = get_ledger()
        if not ledger:
            return TracesResp(traces=[], count=0)
        traces = ledger.get_recent_traces(limit=limit)
        return TracesResp(traces=traces, count=len(traces))
    except Exception as e:
        logger.error(f"List traces error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/observability/trace/{trace_id}", response_model=TraceDetailsResp)
async def get_trace_details(trace_id: str):
    """Get complete trace for replay"""
    try:
        from shared.python.observability import get_ledger

        ledger = get_ledger()
        if not ledger:
            raise HTTPException(status_code=404, detail="Observability not initialized")
        events = ledger.get_trace(trace_id)
        return TraceDetailsResp(trace_id=trace_id, event_count=len(events), events=[e.to_dict() for e in events])
    except Exception as e:
        logger.error(f"Get trace error: {e}")


async def query_events(
    trace_id: Optional[str] = None,
    session_id: Optional[str] = None,
    adr_id: Optional[str] = None,
    event_type: Optional[str] = None,
    limit: int = 100,
) -> EventsResp:
    """Helper to query events from the shared ledger."""
    try:
        from shared.python.observability import get_ledger
        from shared.python.observability.events import EventType

        ledger = get_ledger()
        if not ledger:
            return EventsResp(events=[], count=0)

        # Convert string event_type to Enum if present
        e_type = None
        if event_type:
            try:
                e_type = EventType(event_type)
            except ValueError:
                pass

        events = ledger.query_events(
            trace_id=trace_id,
            session_id=session_id,
            adr_id=adr_id,
            event_type=e_type,
            limit=limit,
        )

        # Serialize events
        items = [e.to_dict() for e in events]
        return EventsResp(events=items, count=len(items))

    except Exception as e:
        logger.error(f"query_events error: {e}")
        return EventsResp(events=[], count=0)


@app.get("/events", response_model=EventsResp, include_in_schema=False)
async def events_alias(
    trace_id: Optional[str] = None,
    session_id: Optional[str] = None,
    adr_id: Optional[str] = None,
    event_type: Optional[str] = None,
    limit: int = 100,
):
    """Alias for /observability/events expected by some frontend components."""
    return await query_events(
        trace_id=trace_id, session_id=session_id, adr_id=adr_id, event_type=event_type, limit=limit
    )


@app.get("/pulse/stream", include_in_schema=False)
async def pulse_stream_root(interval: float = 2.0):
    """Server-Sent Events root alias for frontend EventSource('/api/pulse/stream')."""

    async def event_generator():
        try:
            while True:
                from shared.python.observability import get_ledger

                ledger = get_ledger()
                stats = ledger.get_stats() if ledger and hasattr(ledger, "get_stats") else {"status": "no-ledger"}
                payload = {"type": "pulse", "stats": stats}
                yield f"data: {json.dumps(payload, default=str)}\n\n"
                await asyncio.sleep(interval)
        except asyncio.CancelledError:
            return

    return StreamingResponse(event_generator(), media_type="text/event-stream")


# =============================================================================
# üöÄ SERVER ENTRY POINT
# =============================================================================

# Also include the API router at the root so endpoints appear both under
# `/api/...` and directly under `/...` for backward compatibility.
# Include additional routers implementing frontend-expected endpoints
try:
    from backend.api.routers import agents as agents_router
    from backend.api.routers import executive as executive_router
    from backend.api.routers import governance as governance_router
    from backend.api.routers import ops as ops_router
    from backend.api.routers import system as system_router

    app.include_router(system_router.router, prefix="/system")
    app.include_router(governance_router.router, prefix="/governance")
    app.include_router(executive_router.router, prefix="/executive")
    app.include_router(agents_router.router, prefix="/agents")
    app.include_router(ops_router.router, prefix="/ops")
    # Also expose these routers under the /api prefix on the root app so
    # the root OpenAPI generator (used by `/docs`) sees them.
    root_app.include_router(system_router.router, prefix="/api/system")
    root_app.include_router(governance_router.router, prefix="/api/governance")
    root_app.include_router(executive_router.router, prefix="/api/executive")
    root_app.include_router(agents_router.router, prefix="/api/agents")
    root_app.include_router(ops_router.router, prefix="/api/ops")
except Exception as e:
    logger.warning(f"Could not include extended routers: {e}")

root_app.include_router(app.router, prefix="")

# Mount the API under /api on the root app and expose `app` as the root ASGI
# application for uvicorn and other runners.
root_app.mount("/api", app)

# Reassign module-level `app` to the root app so callers like
# `uvicorn backend.api.server:app` run the combined application.
app = root_app

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="127.0.0.1", port=8000)
