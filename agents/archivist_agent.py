from typing import List, Optional, Dict, Any, Tuple
import os
import re
import shutil
from pathlib import Path
from difflib import SequenceMatcher
from .base import Agent, AgentResult, Problem, AgentRole
from utils.logging_config import get_logger
from kb.schemas import now

logger = get_logger(__name__)


class ArchivistAgent(Agent):
    """
    ğŸ“œ Sovereign Archivist (Council Clerk) - PROACTIVE MODE
    
    Responsibility: 
    Maintains the integrity and freshness of the Sovereign Archive 
    (Policies, Procedures, ADRs). Monitors for documentation gaps 
    and policy contradictions.
    
    ENHANCED CAPABILITIES:
    - Detects policies referenced in ADRs but missing as files
    - Generates policy drafts automatically
    - Submits formal requests for missing documentation
    - Creates comprehensive audit reports
    """
    
    def __init__(self, agent_id: str, llm_provider: Optional["LLMProvider"] = None):
        super().__init__(agent_id=agent_id, role=AgentRole.ARCHIVIST, llm_provider=llm_provider)
        # Legacy compatibility for local methods
        self.llm_provider = self.llm
        # Fix: Resolve relative to project root (one level up from src if running as module)
        self.docs_root = Path(__file__).resolve().parents[3] / "docs"
        self.policies_dir = self.docs_root / "policies"
        self.drafts_dir = self.policies_dir / "drafts"
        self.archived_dir = self.policies_dir / "archive"
        self.adrs_dir = self.docs_root / "adrs"
        self.procedures_dir = self.docs_root / "procedures"
        self.procedures_dir = self.docs_root / "procedures"
        self._kb = None # To be set by controller
        
        # Transparency: Store logs of the last audit Consultation
        self.last_consultation_logs = [] # List of {prompt: str, response: str, timestamp: str}

        # Central Policy Titles database
        self.policy_titles = {
            "P-OPS-05": "Foundational Autonomy Protocol",
            "P-GOV-01": "Sovereign Approval Authority",
            "P-SEC-02": "External Surface Control",
            "P-OBS-01": "Traceability & Auditability",
            "P-CORE-01": "Core System Integrity",
            "P-GOV-10": "Delegated Decision Matrix",
            "P-SEC-01": "Access Control & Identity",
            "P-DAT-02": "Data Retention & Encryption"
        }

    def _scan_for_policy_references(self) -> List[str]:
        """
        Scan all ADRs for policy references (e.g., P-OPS-05, P-GOV-01).
        Returns list of policy codes found.
        """
        policy_pattern = re.compile(r'P-[A-Z]+-\d+')
        referenced_policies = set()
        
        if not self.adrs_dir.exists():
            return []
        
        for adr_file in self.adrs_dir.glob("*.md"):
            try:
                content = adr_file.read_text(encoding='utf-8')
                matches = policy_pattern.findall(content)
                referenced_policies.update(matches)
            except Exception as e:
                logger.warning(f"Failed to scan {adr_file}: {e}")
        
        return sorted(list(referenced_policies))

    def _check_policy_exists(self, policy_code: str) -> bool:
        """Check if a policy file exists."""
        if not self.policies_dir.exists():
            return False
        
        policy_file = self.policies_dir / f"{policy_code}.md"
        return policy_file.exists()

    def detect_missing_policies(self) -> List[str]:
        """
        Detect policies that are referenced but don't have corresponding files.
        """
        referenced = self._scan_for_policy_references()
        missing = [p for p in referenced if not self._check_policy_exists(p)]
        
        logger.info(f"ğŸ“‹ Policy Scan: {len(referenced)} referenced, {len(missing)} missing")
        return missing

    def generate_policy_draft(self, policy_code: str) -> str:
        """
        Generate a policy draft based on the policy code.
        This is a template that will be refined by LLM or human review.
        """
        # Extract policy type from code (e.g., P-OPS-05 -> OPS)
        parts = policy_code.split('-')
        policy_type = parts[1] if len(parts) > 1 else "GENERAL"
        
        title = self.policy_titles.get(policy_code, f"{policy_type} Policy")
        
        draft = f"""# {policy_code}: {title}

**Status:** DRAFT  
**Effective Date:** TBD  
**Owner:** Office of the CEO  
**Department:** {policy_type}

---

## 1. Purpose

[To be defined: What is the purpose of this policy?]

---

## 2. Scope

This policy applies to:
- [Define scope]

---

## 3. Policy Statement

[Core policy rule/principle]

---

## 4. Requirements

All [agents/systems/departments] **SHALL**:

1. [Requirement 1]
2. [Requirement 2]
3. [Requirement 3]

---

## 5. Enforcement

Violations of this policy may result in:
- [Consequence 1]
- [Consequence 2]

---

## 6. Related Documents

- [Related ADRs]
- [Related Procedures]

---

**This is a DRAFT policy generated by ArchivistAgent. Requires sovereign review and approval.**
"""
        return draft

    def _gather_context_snippets(self, policy_code: str, limit_chars: int = 8000) -> str:
        """
        Aggregate contextual snippets from ADRs and docs to guide LLM generation.
        Enhanced: Prioritizes full files where the code is mentioned.
        """
        snippets = []
        # Priority 1: Full files containing the code
        all_paths = list(self.adrs_dir.glob("*.md")) + list(self.docs_root.glob("*.md")) + list(self.policies_dir.glob("*.md"))
        
        for p in all_paths:
            try:
                text = p.read_text(encoding="utf-8")
                if policy_code in text:
                    snippets.append(f"--- FILE: {p.name} ---\n{text}")
            except Exception:
                continue
        
        # Priority 2: General context if snippets are low
        if len("\n\n".join(snippets)) < 2000:
             for p in all_paths:
                if len("\n\n".join(snippets)) > limit_chars: break
                try: snippets.append(f"--- REF: {p.name} ---\n{p.read_text(encoding='utf-8')[:1000]}")
                except Exception: continue

        ctx = "\n\n".join(snippets)
        return ctx[:limit_chars]

    async def synthesize_strategic_brief(self, plan_data: Dict[str, Any]) -> str:
        """
        Phase 1: Synthesis Step.
        The Archivist 'reads' the plan and creates a Strategic Brief to guide drafting.
        """
        if not self.llm:
            return "No LLM provider available for synthesis."

        raw_analysis = plan_data.get("consultant_plan", {}).get("raw_analysis", "")
        critique = plan_data.get("consultant_plan", {}).get("critique", "")
        
        prompt = f"""You are the Corporate Communications Director. 
Review the following Strategic Advice from the External Consultant and synthesize it into a BRIEF, HIGH-LEVEL EXECUTIVE SUMMARY (Strategic Brief) in ARABIC.

STRICT FOCUS:
- What are the 3-5 non-negotiable requirements for our sovereign archive?
- What specific Arabic terminology MUST we use to sound professional and executive?
- Ignore generic advice; focus on actionable mandates for the Archivist.

CONSULTANT ADVICE:
{critique}
{raw_analysis}

OUTPUT FORMAT:
# Ø§Ù„Ù…ÙˆØ¬Ø² Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ (Strategic Brief)
[Your executive synthesis in formal Arabic]
"""
        try:
            from core.llm import LLMRequest
            request = LLMRequest(prompt=prompt, temperature=0.3)
            resp = await self.llm.generate(request)
            return resp.content if hasattr(resp, 'content') else str(resp)
        except Exception as e:
            logger.error(f"Synthesis failed: {e}")
            return f"Synthesis error: {e}"

    async def generate_policy_with_llm(self, policy_code: str, context: str = "", strategic_brief: str = "") -> str:
        """Generates policy content using LLM with context and strategic brief."""
        logger.info(f"ğŸ¤– Generating content for {policy_code} using LLM...")
        
        if not self.llm:
            logger.warning("âš ï¸ LLM not available, using template-based generation")
            return self.generate_policy_draft(policy_code)
        
        title = self.policy_titles.get(policy_code, f"Policy {policy_code}")
        contextual_snippets = self._gather_context_snippets(policy_code)
        
        prompt = f"""You are a Strategic Corporate Governance Manager. Your task is to draft a PROFESSIONAL, SEALED, and LEGALLY RIGOROUS policy document. 

LANGUAGE: You MUST write the entire document in ARABIC (Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©). Use professional, executive-level Arabic terms (e.g., 'Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ù…Ù„', 'Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª', 'Ø§Ù„Ø¥Ù†ÙØ§Ø°').

STRATEGIC MANDATE (Director's Brief):
{strategic_brief}

STRICT RULES:
1. NO PLACEHOLDERS. No '[To be defined]' or '[Requirement 1]'. 
2. Use the provided context to synthesize REAL, actionable rules.
3. Tone: Formal and Sovereign.

Policy Code: {policy_code}
Policy Title: {title}

--- CONTEXT FROM AUDIT ---
{context}

--- CONTEXT FROM REPOSITORY ---
{contextual_snippets}

STRICT OUTPUT FORMAT (Markdown):

# {policy_code}: [Title in Arabic]

**Ø§Ù„Ø­Ø§Ù„Ø©:** Ù…Ø³ÙˆØ¯Ø© Ù…Ø¹ØªÙ…Ø¯Ø©
**ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ†ÙÙŠØ°:** TBD
**Ø§Ù„Ù…Ø§Ù„Ùƒ:** Ù…ÙƒØªØ¨ Ø±Ø¦ÙŠØ³ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©

## 1. Ø§Ù„ØºØ±Ø¶ (Purpose)
[Explain WHY this is needed in professional Arabic]

## 2. Ø§Ù„Ù†Ø·Ø§Ù‚ (Scope)
[Who this applies to]

## 3. Ø¨ÙŠØ§Ù† Ø§Ù„Ø³ÙŠØ§Ø³Ø© (Policy Statement)
[The core mandate]

## 4. Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª (Requirements)
[CRITICAL: Detailed 'MUST' requirements in Arabic based on the audit feedback. No placeholders.]

## 5. Ø§Ù„Ø¥Ù†ÙØ§Ø° ÙˆØ§Ù„ØªØ¨Ø¹Ø§Øª (Enforcement & Consequences)
[Specific consequences for non-compliance]

## 6. Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
[Links to ADRs]

---
**ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ø­ÙˆÙƒÙ…Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠ Ù„Ù„Ø¯ÙˆÙ„Ø©**
"""
        try:
            from ..core.llm import LLMRequest
            from datetime import datetime
            
            request = LLMRequest(prompt=prompt, temperature=0.3, max_tokens=2000)
            response = await self.llm.generate(request)
            
            # Record for Transparency
            self.last_consultation_logs.append({
                "policy_code": policy_code,
                "prompt": prompt,
                "response": response.content,
                "timestamp": datetime.now().isoformat()
            })
            
            logger.info(f"âœ… Generated policy {policy_code} via LLM consultation")
            return response.content
        except Exception as e:
            logger.error(f"âŒ LLM consultation failed: {e}, falling back to template")
            return self.generate_policy_draft(policy_code)

    def detect_policy_contradictions(self, kb) -> List[Dict[str, str]]:
        """
        ÙØ­Øµ Ø§Ù„ØªØ¶Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚.
        
        Detect contradictions between policies, ADRs, and procedures.
        Returns list of potential conflicts.
        """
        contradictions = []
        
        # Example: Check if ADRs reference policies that don't exist
        # This is a simplified version - can be expanded with LLM analysis
        
        if not self.adrs_dir.exists():
            return contradictions
        
        for adr_file in self.adrs_dir.glob("*.md"):
            try:
                content = adr_file.read_text(encoding='utf-8')
                
                # Check for "REJECTED" ADRs that might conflict with "ACCEPTED" ones
                if "Status:** âœ… ACCEPTED" in content or "Status: ACCEPTED" in content:
                    # Look for contradictory statements
                    if "No Agent is permitted" in content and "Autonomous Execution" in content:
                        contradictions.append({
                            "type": "POTENTIAL_CONFLICT",
                            "file": str(adr_file),
                            "description": "ADR mentions both 'No Agent is permitted' and 'Autonomous Execution'"
                        })
            except Exception as e:
                logger.warning(f"Failed to check {adr_file}: {e}")
        
        return contradictions

    async def check_document_coherence(self, kb) -> Dict[str, Any]:
        """
        Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ±Ø§Ø¨Ø· Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙˆØ¹Ø¯Ù… ØªØ¶Ø§Ø±Ø¨Ù‡Ø§.
        
        Comprehensive coherence check across all governance documents.
        """
        coherence_report = {
            "status": "COHERENT",
            "issues": [],
            "recommendations": []
        }
        
        # 1. Check for missing policy files
        missing_policies = self.detect_missing_policies()
        if missing_policies:
            coherence_report["issues"].append({
                "severity": "HIGH",
                "type": "MISSING_POLICIES",
                "details": f"Policies referenced but not documented: {', '.join(missing_policies)}"
            })
            coherence_report["status"] = "GAPS_DETECTED"
        
        # 2. Check for contradictions
        contradictions = self.detect_policy_contradictions(kb)
        if contradictions:
            coherence_report["issues"].append({
                "severity": "MEDIUM",
                "type": "POTENTIAL_CONTRADICTIONS",
                "details": contradictions
            })
            if coherence_report["status"] == "COHERENT":
                coherence_report["status"] = "REVIEW_NEEDED"
        
        # 3. Check for orphaned ADRs (ADRs not linked to any policy)
        # This would require more sophisticated analysis
        
        # 4. Generate recommendations
        if missing_policies:
            coherence_report["recommendations"].append(
                "Create missing policy files to ensure complete documentation"
            )
        
        if contradictions:
            coherence_report["recommendations"].append(
                "Review potential contradictions and clarify policy boundaries"
            )
        
        return coherence_report

    async def conduct_deep_audit(self, kb, consultant_agent=None, mediator_agent=None) -> Dict[str, Any]:
        """
        Runs audit + coherence check and optionally consults with external consultant.
        """
        audit = await self.audit_kb(kb)
        coherence = await self.check_document_coherence(kb)
        consultant_feedback = None

        if consultant_agent:
            try:
                content = f"AUDIT: {audit}\nCOHERENCE: {coherence}"
                review = await consultant_agent.review_document_draft(
                    doc_type="Audit Summary",
                    content=content
                )
                
                # Phase 4: Direct Feedback Loop - Challenge if too generic
                if review.get("score", 0) < 50 or "[To be defined]" in str(review.get("critique", "")):
                    logger.info("ğŸ”„ Consultant feedback too generic, challenging for more detail...")
                    review = await consultant_agent.review_document_draft(
                        doc_type="Audit Summary (Challenged for Detail)",
                        content=f"{content}\n\nDIRECTIVE: Your previous analysis was too high-level. Provide SPECIFIC, ACTIONABLE requirements for a Sovereign entity."
                    )
                
                consultant_feedback = review
            except Exception as e:
                logger.warning(f"Consultant review failed: {e}")

        result = {
            "status": audit.get("status", "UNKNOWN"),
            "audit": audit,
            "coherence": coherence,
            "consultant_review": consultant_feedback
        }

        self.last_consultation_logs.append({
            "policy_code": "AUDIT",
            "prompt": "DEEP_AUDIT",
            "response": str(result),
            "timestamp": str(now())
        })
        self.last_consultation_logs = self.last_consultation_logs[-50:]
        return result


    async def audit_kb(self, kb) -> Dict[str, Any]:
        """
        Performs a comprehensive audit of the Knowledge Base and file system.
        """
        # Check KB
        kb_policies = len(kb.policies) if hasattr(kb, 'policies') else 0
        kb_procedures = len(kb.procedures) if hasattr(kb, 'procedures') else 0
        kb_decisions = len(kb.human_decisions) if hasattr(kb, 'human_decisions') else 0
        
        # Check file system
        missing_policies = self.detect_missing_policies()
        
        # Check if policies directory exists
        policies_dir_exists = self.policies_dir.exists()
        
        stats = {
            "policies_count_kb": kb_policies,
            "procedures_count": kb_procedures,
            "decisions_count": kb_decisions,
            "policies_dir_exists": policies_dir_exists,
            "missing_policy_files": missing_policies,
            "status": "HEALTHY",
            "gaps": []
        }
        
        # Detect gaps
        if not policies_dir_exists:
            stats["gaps"].append("CRITICAL: docs/policies/ directory does not exist")
            stats["status"] = "CRITICAL"
        
        if missing_policies:
            stats["gaps"].append(f"Missing {len(missing_policies)} policy files: {', '.join(missing_policies)}")
            stats["status"] = "WARNING" if stats["status"] != "CRITICAL" else "CRITICAL"
        
        if kb_procedures == 0:
            stats["gaps"].append("Missing Standard Operating Procedures (SOPs)")
            if stats["status"] == "HEALTHY":
                stats["status"] = "WARNING"
        
        return stats

    async def create_missing_policy_files(self, missing_policies: List[str]) -> Dict[str, str]:
        """
        Create draft files for missing policies.
        Returns dict of {policy_code: file_path}
        """
        # Ensure policies directory exists
        self.policies_dir.mkdir(parents=True, exist_ok=True)
        
        created_files = {}
        
        for policy_code in missing_policies:
            draft = self.generate_policy_draft(policy_code)
            policy_file = self.policies_dir / f"{policy_code}.md"
            
            try:
                policy_file.write_text(draft, encoding='utf-8')
                created_files[policy_code] = str(policy_file)
                logger.info(f"âœ… Created policy draft: {policy_file}")
            except Exception as e:
                logger.error(f"âŒ Failed to create {policy_code}: {e}")
        
        return created_files

    async def _analyze(self, problem: Problem, kb) -> AgentResult:
        """
        Analyzes the state of documentation and proposes enhancements.
        PROACTIVE MODE: Also creates missing policy drafts.
        
        All reports pass through SecretaryAgent before reaching CEO.
        """
        audit = await self.audit_kb(kb)
        
        analysis = f"Sovereign Archive Status: {audit['status']}. "
        analysis += f"KB contains {audit['policies_count_kb']} policies and {audit['procedures_count']} procedures. "
        
        if audit['missing_policy_files']:
            analysis += f"\n\nâš ï¸ DETECTED {len(audit['missing_policy_files'])} MISSING POLICY FILES: {', '.join(audit['missing_policy_files'])}"
        
        recs = []
        
        # Remove any automatic draft creation; only report findings
        if audit["status"] == "WARNING" or audit["status"] == "CRITICAL":
            recs.append("EXPAND_PROCEDURE_LIBRARY")
            recs.append("REFINE_GOVERNANCE_DOCS")
        
        if not audit["policies_dir_exists"]:
            recs.append("CREATE_POLICIES_DIRECTORY")
        
        return AgentResult(
            agent_id=self.agent_id,
            role=self.role,
            analysis=analysis,
            recommendations=recs,
            concerns=audit.get("missing_policy_files", []),
            confidence=0.95
        )

    async def submit_report_to_ceo(self, kb, secretary_agent=None, consultant_agent=None, mediator_agent=None) -> Dict[str, Any]:
        """
        Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ù„Ù„Ø±Ø¦ÙŠØ³.
        Workflow:
        1. Archivist generates findings.
        2. [New] Mediator controls access to Consultant (Cost/Traffic Control).
        3. Secretary formats and delivers.
        """
        # Generate findings
        audit = await self.audit_kb(kb)
        coherence = await self.check_document_coherence(kb)
        severity = audit.get("status", "MEDIUM")
        
        consultant_feedback = []
        
        # Route through Mediator if available
        if mediator_agent and consultant_agent:
            try:
                msg = f"Requesting consultation for Audit Report (Severity: {severity})"
                logger.info(f"ğŸ§  Synthesizing Strategic Brief for plan...")
                logger.info(f"ğŸš¦ Mediator Traffic Control: {msg}")
                
                request_data = {
                    "severity": severity,
                    "doc_type": "Audit Report",
                    "content": str(audit) + "\n" + str(coherence)
                }
                
                # Ask Mediator for permission/execution
                mediation_result = await mediator_agent.request_consultation(
                    requester_id=self.agent_id,
                    request_data=request_data,
                    consultant_agent=consultant_agent
                )
                
                if mediation_result["approved"]:
                    consultant_feedback.append(mediation_result["consultation_result"])
                    logger.info("âœ… Mediator Approved Consultation")
                else:
                    logger.info(f"â›” Mediator Denied Consultation: {mediation_result['reason']}")
                    consultant_feedback.append({"critique": f"Consultation Skipped: {mediation_result['reason']}", "score": -1})
                    
            except Exception as e:
                logger.warning(f"Mediator/Consultant failed: {e}")
        
        # Fallback: Direct consult if no Mediator (optional, but requested to enforce mediation)
        elif consultant_agent:
             # Just do direct call if no mediator provided (Legacy mode)
             pass
             
        # Prepare raw report
        raw_report = {
            "from": "ArchivistAgent",
            "to": "CEO",
            "timestamp": str(now()),
            "audit": audit,
            "coherence": coherence,
            "consultant_review": consultant_feedback, 
            "priority": "HIGH" if severity == "CRITICAL" else "MEDIUM"
        }
        
        # Route through Secretary
        if secretary_agent:
            return await secretary_agent.format_report_for_ceo(raw_report)
            
        return raw_report

    async def report_blocker(self, blocker_type: str, details: str, severity: str = "HIGH") -> Dict[str, str]:
        """
        Ø±ÙØ¹ ØªÙ‚Ø±ÙŠØ± Ù…Ø¹ÙˆÙ‚ Ù„Ù„Ø±Ø¦ÙŠØ³ Ø¹Ø¨Ø± Ø§Ù„Ù…ÙƒØªØ¨.
        
        Report a blocker to CEO through proper channels.
        """
        blocker_report = {
            "type": "BLOCKER",
            "severity": severity,
            "blocker_type": blocker_type,
            "details": details,
            "from": self.agent_id,
            "timestamp": str(now()),
            "requires_action": True
        }
        
        logger.critical(f"ğŸš¨ BLOCKER REPORTED: {blocker_type} - {details}")
        
        # This should be routed through SecretaryAgent in production
        # For now, just log and return
        return blocker_report

    async def create_drafts_from_plan(self, plan_data: Dict[str, Any], consultant_agent=None) -> List[str]:
        """
        Creates draft policy files in the drafts folder based on the improvement plan.
        """
        self.drafts_dir.mkdir(parents=True, exist_ok=True)
        created_drafts = []

        # Access content
        description = plan_data.get("consultant_plan", {}).get("description", "")
        raw_analysis = plan_data.get("consultant_plan", {}).get("raw_analysis", "")
        full_text = str(description) + "\n" + str(raw_analysis)
        required_from_plan = set(plan_data.get("consultant_plan", {}).get("required_policies") or [])

        # 1. Synthesis Step: Create the Strategic Brief
        strategic_brief = plan_data.get("strategic_brief") or await self.synthesize_strategic_brief(plan_data)
        logger.info(f"ğŸ§  Strategic Brief Status: {len(strategic_brief) if strategic_brief else 'Missing'} chars")

        # 1.5 Advanced Extraction: Try to find structured policy list
        policy_codes = self._extract_policies_from_text(full_text)
        policy_codes.update(required_from_plan)
        # Remove owner-note pseudo codes
        policy_codes = {c for c in policy_codes if ".owner-notes" not in str(c)}
        policy_codes.update(required_from_plan)
        
        if not policy_codes:
            # Fallback: Check if the consultant specifically mentioned a code in the summary
            import re
            policy_codes = set(re.findall(r'P-[A-Z]+-\d+', full_text))
            
        if not policy_codes:
            logger.info("âš ï¸ No specific policy codes identified, generating P-GEN-01 fallback.")
            policy_codes = {"P-GEN-01"}

        state = self._load_state()
        processed_codes = set(state.get("processed_codes", []))
        existing_policies = {p.stem for p in self.policies_dir.glob("*.md")} if self.policies_dir.exists() else set()
        existing_drafts = {p.stem for p in self.drafts_dir.glob("*.md")} if self.drafts_dir.exists() else set()

        for code in policy_codes:
            draft_file = self.drafts_dir / f"{code}.md"

            # If a draft already exists, keep it but still mark processed and count it
            if draft_file.exists():
                processed_codes.add(code)
                created_drafts.append(code)
                logger.info(f"â­ï¸ Draft already exists for {code}, keeping current draft.")
                continue

            processed_codes.add(code)
            draft_content = None

            # If there is an active policy, copy it into drafts so the owner can review/ratify/update it
            if code in existing_policies:
                try:
                    src_file = self.policies_dir / f"{code}.md"
                    draft_content = src_file.read_text(encoding="utf-8")
                    logger.info(f"ğŸ“„ Copied existing policy into drafts for review: {src_file} -> {draft_file}")
                except Exception as e:
                    logger.warning(f"Failed to copy existing policy {code} into drafts, will regenerate: {e}")

            # If no existing policy or copy failed, generate a fresh draft with context
            if draft_content is None:
                llm_context = f"""
                IMPROVEMENT PLAN CONTEXT:
                Description: {description}
                Full Analysis: {raw_analysis}
                
                OBJECTIVE:
                Extract the core rules suggested by the consultant and formalize them into policy requirements.
                Address the specific flaws identified in the analysis.
                """
                draft_content = await self.generate_policy_with_llm(code, context=llm_context, strategic_brief=strategic_brief)
            
            # Write to drafts folder
            draft_file.write_text(draft_content, encoding='utf-8')
            created_drafts.append(code)
            logger.info(f"ğŸ“ Created ROBUST DRAFT: {draft_file}")
            self.last_consultation_logs.append({
                "policy_code": code,
                "prompt": "DRAFT_CREATED",
                "response": f"Draft generated from plan for {code}",
                "timestamp": str(now())
            })
            self.last_consultation_logs = self.last_consultation_logs[-50:]
        
        state["processed_codes"] = sorted(list(processed_codes))
        self._save_state(state)

        # Deduplicate after draft generation
        if consultant_agent:
            await self.deduplicate_policies(consultant_agent)

        return created_drafts

    def _extract_policies_from_text(self, text: str) -> set:
        """
        Attempts to find policy codes embedded in various formats (JSON, tags, lists).
        """
        codes = set()
        
        # A. Look for JSON block
        try:
            # Simple regex to find JSON-like structures
            import json
            json_blocks = re.findall(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
            for block in json_blocks:
                data = json.loads(block)
                if isinstance(data, dict):
                    # Look for "policies" or "required_policies" keys
                    list_data = data.get("policies") or data.get("required_policies")
                    if isinstance(list_data, list):
                        codes.update([str(p).split(":")[0].strip() for p in list_data])
        except Exception as e:
            logger.debug(f"JSON extraction failed: {e}")

        # B. Look for specific Tag: [POLICY: P-XXX-NN]
        tag_matches = re.findall(r'\[POLICY:\s*(P-[A-Z]+-\d+)\]', text)
        codes.update(tag_matches)
        
        # C. Look for explicit mentions in markdown headers or lists
        # e.g. "## Proposed Policy: P-SEC-03"
        header_matches = re.findall(r'Proposed Policy:\s*(P-[A-Z]+-\d+)', text)
        codes.update(header_matches)

        return codes

    async def ratify_drafts(self) -> List[str]:
        """
        Moves all files from drafts folder to policies folder.
        This is the formal ratification step.
        """
        if not self.drafts_dir.exists():
            return []
            
        ratified_policies = []
        
        for draft_file in self.drafts_dir.glob("*.md"):
            # Destination path
            policy_file = self.policies_dir / draft_file.name
            try:
                draft_content = draft_file.read_text(encoding="utf-8")
                # If a policy already exists, archive it first, then ensure target is clear
                if policy_file.exists():
                    self.archived_dir.mkdir(parents=True, exist_ok=True)
                    archive_target = self.archived_dir / policy_file.name
                    if archive_target.exists():
                        import time
                        archive_target = self.archived_dir / f"{policy_file.stem}-{int(time.time())}.md"
                    try:
                        policy_file.replace(archive_target)
                        logger.info(f"ğŸ“¦ Archived existing policy before ratify: {archive_target}")
                        self._purge_logs_for_code(policy_file.stem)
                    except Exception as e:
                        logger.warning(f"Archive move failed for {policy_file}: {e}, will delete target and continue")
                        try:
                            policy_file.unlink()
                        except Exception:
                            pass
                # Write draft content to policy file (overwrite)
                policy_file.write_text(draft_content, encoding="utf-8")
                draft_file.unlink()
                ratified_policies.append(draft_file.stem)
                logger.info(f"âœ… RATIFIED Policy: {policy_file}")
            except Exception as e:
                logger.error(f"Ratify failed for {draft_file}: {e}")
            
        return ratified_policies

    def _load_policy_files(self) -> List[Tuple[Path, str]]:
        """
        Load all policy and draft files with their content.
        Returns list of (path, content)
        """
        files = []
        for folder in [self.policies_dir, self.drafts_dir]:
            if folder.exists():
                for f in folder.glob("*.md"):
                    try:
                        files.append((f, f.read_text(encoding="utf-8")))
                    except Exception as e:
                        logger.warning(f"Failed to read {f}: {e}")
        return files

    def find_duplicate_policies(self, similarity_threshold: float = 0.8) -> List[Dict[str, Any]]:
        """
        Detect potential duplicate policies based on title/content similarity.
        Returns list of {primary, duplicate, similarity}
        """
        files = self._load_policy_files()
        candidates = []

        def _title(text: str) -> str:
            for line in text.splitlines():
                if line.strip().startswith("#"):
                    return line.strip("# ").strip()
            return text[:80]

        for i, (path_a, text_a) in enumerate(files):
            for path_b, text_b in files[i+1:]:
                title_a, title_b = _title(text_a), _title(text_b)
                title_sim = SequenceMatcher(None, title_a.lower(), title_b.lower()).ratio()

                # Use a larger slice to reduce false positives on short intros
                body_sim = SequenceMatcher(None, text_a[:4000], text_b[:4000]).ratio()
                sim = max(title_sim, body_sim)

                # If titles are identical (ignoring case), lower the bar
                effective_threshold = similarity_threshold
                if title_a.lower().strip() == title_b.lower().strip():
                    effective_threshold = min(similarity_threshold, 0.65)

                if sim >= effective_threshold:
                    # Prefer non-draft as primary; otherwise keep the first
                    primary, duplicate = (path_a, path_b)
                    if "drafts" in str(primary) and "drafts" not in str(duplicate):
                        primary, duplicate = duplicate, primary
                    candidates.append({
                        "primary": str(primary),
                        "duplicate": str(duplicate),
                        "similarity": round(sim, 3),
                        "title_a": title_a,
                        "title_b": title_b
                    })
        return candidates

    async def deduplicate_policies(self, consultant_agent=None, similarity_threshold: float = 0.8) -> Dict[str, Any]:
        """
        Merge duplicates using consultant guidance. Duplicate files are moved to archive.
        """
        duplicates = self.find_duplicate_policies(similarity_threshold=similarity_threshold)
        if not duplicates:
            return {"status": "NO_DUPLICATES"}

        self.archived_dir.mkdir(parents=True, exist_ok=True)
        actions = []

        for dup in duplicates:
            primary_path = Path(dup["primary"])
            duplicate_path = Path(dup["duplicate"])

            # Skip if already archived or if same file path
            if primary_path == duplicate_path or not duplicate_path.exists() or not primary_path.exists():
                continue

            try:
                primary_text = primary_path.read_text(encoding="utf-8")
                duplicate_text = duplicate_path.read_text(encoding="utf-8")

                merged_text = primary_text
                if consultant_agent:
                    prompt = f"""
You are the Archivist Consultant. Merge the two policy documents into ONE final policy.
Keep the stronger requirements, resolve conflicts, and avoid placeholders.
Return clean Markdown for the final policy.

--- PRIMARY ---
{primary_text}

--- DUPLICATE ---
{duplicate_text}
"""
                    from ..core.llm import LLMRequest
                    request = LLMRequest(prompt=prompt, temperature=0.2, max_tokens=1800)
                    response = await consultant_agent.llm.generate(request)
                    merged_text = response.content

                primary_path.write_text(merged_text, encoding="utf-8")

                # Archive duplicate file
                archived_target = self.archived_dir / duplicate_path.name
                duplicate_path.rename(archived_target)

                actions.append({
                    "primary": str(primary_path),
                    "archived": str(archived_target),
                    "similarity": dup["similarity"],
                    "title_a": dup.get("title_a"),
                    "title_b": dup.get("title_b")
                })

                logger.info(f"ğŸ§¹ Merged duplicate {duplicate_path} -> {primary_path}")
                self.last_consultation_logs.append({
                    "policy_code": primary_path.stem,
                    "prompt": "DEDUP_MERGE",
                    "response": f"Merged with {duplicate_path.name} (sim={dup['similarity']}), titles: {dup.get('title_a')} | {dup.get('title_b')}",
                    "timestamp": str(now())
                })
                self.last_consultation_logs = self.last_consultation_logs[-50:]
            except Exception as e:
                logger.error(f"Dedup failed for {dup}: {e}")

        return {"status": "DEDUP_DONE", "actions": actions, "count": len(actions)}

    async def apply_owner_notes(self, filename: str, notes: str, is_draft: bool, consultant_agent=None) -> Dict[str, Any]:
        """
        Interpret owner instructions and produce an updated draft.
        - If target is a policy, the updated version is written to drafts_dir with same filename.
        - If target is a draft, it is overwritten with the updated content.
        """
        base_dir = self.drafts_dir if is_draft else self.policies_dir
        source_path = base_dir / filename
        if not source_path.exists():
            raise FileNotFoundError("Document not found")

        try:
            original_text = source_path.read_text(encoding="utf-8")
            target_path = self.drafts_dir / filename  # always land in drafts for review
            self.drafts_dir.mkdir(parents=True, exist_ok=True)

            # Backup the previous draft to keep traceability
            if target_path.exists():
                import time
                backup_suffix = int(time.time())
                backup_path = target_path.parent / f"{target_path.stem}-orig-{backup_suffix}.md"
                try:
                    target_path.replace(backup_path)
                except Exception as e:
                    logger.warning(f"Backup failed for {target_path}: {e}")

            # Build updated text (replace instead of appending duplicate content)
            if consultant_agent and consultant_agent.llm:
                from ..core.llm import LLMRequest
                contextual_snippets = self._gather_context_snippets(Path(filename).stem)
                prompt = f"""
You are the Sovereign Archivist Consultant. Draft an updated version based on the owner's directives.

Instructions from owner:
{notes}

Current policy text:
{original_text}

Context from ADRs/Docs/Policies:
{contextual_snippets}

Requirements:
- Keep the policy code and structure.
- Apply the requested changes explicitly (rewrite, align with new policies, pause/retire clauses if asked).
- Avoid placeholders; produce a ready draft in Markdown.
"""
                request = LLMRequest(prompt=prompt, temperature=0.25, max_tokens=2000)
                response = await consultant_agent.llm.generate(request)
                updated_text = response.content
            else:
                # If no consultant, at least append the owner's note section (single version)
                updated_text = f"{original_text}\n\n## ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø§Ù„Ù…Ø§Ù„Ùƒ\n{notes}\n"

            target_path.write_text(updated_text, encoding="utf-8")

            self.last_consultation_logs.append({
                "policy_code": Path(filename).stem,
                "prompt": "OWNER_NOTES_APPLIED",
                "response": f"Updated draft at {target_path.name}\nOwner notes: {notes}",
                "timestamp": str(now())
            })
            self.last_consultation_logs = self.last_consultation_logs[-50:]

            return {
                "status": "UPDATED_DRAFT",
                "draft_file": str(target_path.name),
                "notes_applied": True
            }
        except Exception as e:
            logger.error(f"Failed to apply owner notes: {e}")
            raise

    # --- STATE PERSISTENCE ---
    def _load_state(self) -> Dict[str, Any]:
        """Loads state from KB metadata if available."""
        if self._kb:
            return self._kb.get_metadata("archivist_state", {"processed_codes": []})
        
        # Fallback for initialization or standalone modes
        try:
            from ..governance.icgl import ICGL
            kb = ICGL().kb
            return kb.get_metadata("archivist_state", {"processed_codes": []})
        except Exception:
            return {"processed_codes": []}

    def _save_state(self, state: Dict[str, Any]):
        """Persists state to KB metadata."""
        if self._kb:
            self._kb.save_metadata("archivist_state", state)
            return

        try:
            from ..governance.icgl import ICGL
            kb = ICGL().kb
            kb.save_metadata("archivist_state", state)
        except Exception as e:
            logger.warning(f"Failed to save archivist state to KB: {e}")

    # --- POLICY LIFECYCLE ACTIONS ---
    def _remove_processed_code(self, code: str):
        state = self._load_state()
        processed = set(state.get("processed_codes", []))
        if code in processed:
            processed.remove(code)
            state["processed_codes"] = sorted(list(processed))
            self._save_state(state)

    def _purge_logs_for_code(self, code: str):
        """Remove timeline logs for a specific policy code."""
        if not self.last_consultation_logs:
            return
        self.last_consultation_logs = [
            log for log in self.last_consultation_logs
            if log.get("policy_code") not in (code, code.upper(), code.lower())
        ]

    def archive_policy(self, filename: str) -> str:
        """
        Move an active policy to archive folder (disable it).
        """
        source = self.policies_dir / filename
        if not source.exists():
            raise FileNotFoundError("Policy not found")
        self.archived_dir.mkdir(parents=True, exist_ok=True)
        target = self.archived_dir / filename
        source.rename(target)
        self._remove_processed_code(Path(filename).stem)
        self._purge_logs_for_code(Path(filename).stem)
        logger.info(f"ğŸ“¦ Archived policy {source} -> {target}")
        return str(target)

    def delete_policy(self, filename: str, is_draft: bool = False) -> str:
        """
        Delete a policy or draft file.
        """
        base_dir = self.drafts_dir if is_draft else self.policies_dir
        target = base_dir / filename
        if not target.exists():
            raise FileNotFoundError("File not found")
        target.unlink()
        self._remove_processed_code(Path(filename).stem)
        self._purge_logs_for_code(Path(filename).stem)
        logger.info(f"ğŸ—‘ï¸ Deleted file {target}")
        return str(target)

    async def generate_improvement_plan(self, consultant_agent, kb=None) -> Dict[str, Any]:
        """
        Safe Experiment:
        Audits the current document structure and consults with AI
        for improvements WITHOUT making changes.
        """
        state = self._load_state()
        processed_codes = set(state.get("processed_codes", []))

        # 1. Gather Inventory + semantic gap hints from docs
        inventory = {
            "policies": [],
            "adrs": [],
            "root_docs": [],
            "doc_topics": []
        }

        # Scan Policies
        if self.policies_dir.exists():
            for f in self.policies_dir.glob("*.md"):
                # ØªØ®Ø·Ù‘Ù Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø±Ø§ÙÙ‚Ø©
                if ".owner-notes" in f.name:
                    continue
                inventory["policies"].append(f.name)
                
        # Scan ADRs
        if self.adrs_dir.exists():
            for f in self.adrs_dir.glob("*.md"):
                inventory["adrs"].append(f.name)
                
        # Scan Root Docs and extract topics (first heading)
        for f in self.docs_root.glob("*.md"):
            inventory["root_docs"].append(f.name)
            try:
                text = f.read_text(encoding="utf-8")
                for line in text.splitlines():
                    if line.strip().startswith("#"):
                        inventory["doc_topics"].append(line.strip().lstrip("#").strip())
                        break
            except Exception:
                continue

        # 2. Consult
        # Also run audit to get missing list as fallback
        audit_snapshot = await self.audit_kb(kb) if kb is not None else {}
        missing_from_audit = audit_snapshot.get("missing_policy_files", []) if isinstance(audit_snapshot, dict) else []

        if consultant_agent:
            prompt_content = f"""
            Current Documentation Structure:
            - Policies: {inventory['policies']}
            - ADRs: {inventory['adrs']}
            - General Docs: {inventory['root_docs']}
            - Already processed policy codes: {sorted(list(processed_codes))}
            
            Task:
            Analyze changes needed and avoid repeating processed codes unless critical drift exists.
            1. Identify missing critical policies (e.g., Access Control, Data Privacy) excluding processed ones.
            2. Highlight relationships/impacts between suggested policies and existing ones.
            3. Suggest a cleaner folder structure if needed.
            4. Propose a renaming scheme if inconsistent.
            
            Output JSON:
            {{
                "missing_policies": ["CODE: Title (e.g. P-SEC-01: Access Control)"],
                "required_policies": ["P-SEC-01", "P-DAT-02"],
                "relations": ["P-SEC-01 impacts P-OPS-05 because ..."],
                "conflicts": ["P-DAT-02 conflicts with P-SEC-02 in logging scope"],
                "structure_feedback": "Detailed analysis of current state",
                "proposed_actions": ["Action 1", "Action 2"]
            }}
            
            CRITICAL: Ensure the "required_policies" key contains a clean list of P-XXX-NN codes.
            """
            
            try:
                # If the consultant has no real intelligence (no API), skip the noisy critique and synthesize a plan
                if not getattr(consultant_agent, "has_intelligence", False):
                    # Use missing from audit or propose baseline + inferred topics from docs
                    baseline_refs = ["P-IR-01", "P-BC-01", "P-VND-01", "P-AI-01"]
                    inferred = [f"P-DOC-{idx+1:02d}" for idx, _ in enumerate(inventory.get("doc_topics", [])[:3])]
                    filtered_required = [c for c in missing_from_audit if c not in processed_codes] or baseline_refs + inferred
                    plan = {
                        "current_state": inventory,
                        "consultant_plan": {
                            "approved": False,
                            "critique": "Ø®Ø·Ø© Ù‡ÙŠÙˆØ±ÙŠØ³ØªÙŠØ©: Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙŠØ§Ø³Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ÙˆÙ…Ø³ÙˆØ¯Ø§Øª Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª.",
                            "required_policies": filtered_required,
                            "relations": [],
                            "structure_feedback": "Offline heuristic plan",
                            "proposed_actions": ["Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ÙˆØ¯Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"]
                        },
                        "status": "PLAN_READY",
                        "next_step": "User Approval"
                    }
                    # PHASE 2: Strategic Intervention - Synthesis
                    strategic_brief = await self.synthesize_strategic_brief(plan)
                    plan["strategic_brief"] = strategic_brief
                    return plan

                # Reuse review_document_draft as a generic pipe for now
                review = await consultant_agent.review_document_draft(
                    doc_type="Structure Audit",
                    content=prompt_content
                )

                # Filter required policies to avoid repeating processed or existing ones
                required = review.get("required_policies", []) or []
                # ØªØ®Ù„Øµ Ù…Ù† Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø§Ù„Ùƒ Ø¥Ù† ÙˆÙØ¬Ø¯Øª Ø¶Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
                required = [c for c in required if ".owner-notes" not in str(c)]
                existing_codes = {Path(p).stem for p in inventory["policies"]}
                # Allow re-proposing processed codes if Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù ÙØ¹Ù„ÙŠØ› ÙÙ‚Ø· ØªØ¬Ù†Ø¨ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ
                filtered_required = [c for c in required if c not in existing_codes]
                if not filtered_required:
                    # If nothing is missing, schedule quality-review for existing policies not already in drafts
                    baseline_refs = ["P-IR-01", "P-BC-01", "P-VND-01", "P-AI-01"]
                    if missing_from_audit:
                        filtered_required = missing_from_audit
                    else:
                        # If baseline policies are absent, propose them; otherwise review existing policies
                        missing_baseline = [c for c in baseline_refs if c not in existing_codes]
                        if missing_baseline:
                            filtered_required = missing_baseline
                            review["critique"] = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù‚Øµ Ø¸Ø§Ù‡Ø± ÙÙŠ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠØ©ØŒ Ù„ÙƒÙ† ÙŠÙ†Ù‚ØµÙ†Ø§ Ø³ÙŠØ§Ø³Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Incident/BC/AI/Vendor)."
                        else:
                            # take all existing policies and plan a QA pass
                            filtered_required = [c for c in existing_codes if c]
                            review["critique"] = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù‚Øµ Ø¸Ø§Ù‡Ø±ØŒ Ø³ÙŠØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³ÙˆØ¯Ø§Øª Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬ÙˆØ¯Ø© Ù„Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©."
                            review["proposed_actions"] = review.get("proposed_actions") or [
                                "ØªØ¬Ù‡ÙŠØ² Ù†Ø³Ø® Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬ÙˆØ¯Ø© Ù„ÙƒÙ„ Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©",
                                "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±/Ø§Ù„ØªØ¹Ø§Ø±Ø¶ Ø¨ÙŠÙ† Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª",
                                "ØªÙˆØ­ÙŠØ¯ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙˆØ§Ù„Ø¨Ù†ÙŠØ©"
                            ]
                # De-duplicate while preserving order
                seen = set()
                filtered_required = [c for c in filtered_required if not (c in seen or seen.add(c))]
                review["required_policies"] = filtered_required
                # Replace repetitive canned critique with concise, current audit-based note
                if missing_from_audit:
                    review["critique"] = f"Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø­Ø§Ù„ÙŠØ§Ù‹: {', '.join(missing_from_audit)}"
                elif filtered_required:
                    review["critique"] = "Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ÙˆØ¯Ø§Øª Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬ÙˆØ¯Ø© Ù„Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©."
                    review["proposed_actions"] = review.get("proposed_actions") or [
                        "ØªØ¬Ù‡ÙŠØ² Ù†Ø³Ø® Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬ÙˆØ¯Ø© Ù„ÙƒÙ„ Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©",
                        "Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±/Ø§Ù„ØªØ¹Ø§Ø±Ø¶ Ø¨ÙŠÙ† Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª",
                        "ØªÙˆØ­ÙŠØ¯ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙˆØ§Ù„Ø¨Ù†ÙŠØ©"
                    ]
                else:
                    review["critique"] = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù‚Øµ Ø¸Ø§Ù‡Ø± ÙÙŠ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ØŒ Ù„ÙƒÙ† ÙŠÙˆØµÙ‰ Ø¨ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¨Ù†ÙŠØ© (ØªÙ†Ø¸ÙŠÙØŒ ØªÙˆØ­ÙŠØ¯ Ø£Ù‚Ø³Ø§Ù…ØŒ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª)."
                # Clear noisy raw_analysis to avoid showing stale English text in UI
                review["raw_analysis"] = ""

                plan = {
                    "current_state": inventory,
                    "consultant_plan": review,
                    "status": "PLAN_READY",
                    "next_step": "User Approval"
                }
                # PHASE 2: Strategic Intervention - Synthesis
                strategic_brief = await self.synthesize_strategic_brief(plan)
                plan["strategic_brief"] = strategic_brief
                return plan
            except Exception as e:
                # Fallback hard if consultant call failed
                filtered_required = [c for c in missing_from_audit if c not in processed_codes] or ["P-GEN-01"]
                return {
                    "current_state": inventory,
                    "consultant_plan": {
                        "approved": False,
                        "critique": f"Consultant unavailable: {e}. Using heuristic fallback.",
                        "required_policies": filtered_required,
                        "relations": [],
                        "structure_feedback": "Offline heuristic plan (error in consultant)",
                        "proposed_actions": ["Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ÙˆØ¯Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"]
                    },
                    "status": "PLAN_READY",
                    "next_step": "User Approval"
                }
        
        return {"error": "No Consultant Available"}
